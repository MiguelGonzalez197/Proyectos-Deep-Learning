{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d97ZnsBPCYTN",
        "outputId": "8aa79de3-dfaf-42f1-825f-c4cd1398f907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Proyectos-Deep-Learning'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 20 (delta 8), reused 3 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (20/20), 34.89 KiB | 1.84 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b Sebastian-Gutierrez https://github.com/MiguelGonzalez197/Proyectos-Deep-Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Ttq8WwCPMGKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Carga de dataset .xslx\n",
        "\n",
        "uploaded=files.upload()\n",
        "nombre_archivo=list(uploaded.keys())[0]\n",
        "df=pd.read_csv(nombre_archivo,sep=\";\",encoding=\"latin1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "mAx2ZMeQCc3J",
        "outputId": "3ae1f571-7382-408d-c968-adf948d9eaaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-02c6d18d-d24f-4daf-abc3-460e4be9ebff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-02c6d18d-d24f-4daf-abc3-460e4be9ebff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Dataset_ExamenesLaboratorio_ConsultaExterna_PatologíasRelacionadas_Obesidad_202405_202411.csv to Dataset_ExamenesLaboratorio_ConsultaExterna_PatologíasRelacionadas_Obesidad_202405_202411.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PreProcesamiento del dataset\n",
        "f=df.fillna(0)\n",
        "\n",
        "cod_dep,map_Dep=pd.factorize(df[\"DEPARTAMENTO\"])\n",
        "df[\"DEPARTAMENTO\"]=cod_dep +1\n",
        "\n",
        "cod_Prov,map_Prov=pd.factorize(df[\"PROVINCIA\"])\n",
        "df[\"PROVINCIA\"]=cod_Prov+1\n",
        "\n",
        "cod_Dist,map_Dist=pd.factorize(df[\"DISTRITO\"])\n",
        "df[\"DISTRITO\"]=cod_Dist+1\n",
        "\n",
        "df['EDAD_PACIENTE'] = pd.cut(\n",
        "    df['EDAD_PACIENTE'],\n",
        "    bins=[0, 10, 20, 30,40,50,60,70,80,90,100,110],\n",
        "    labels=[1, 2, 3,4,5,6,7,8,9,10,11],\n",
        "    right=False\n",
        ")\n",
        "\n",
        "cod_sex,map_Sex=pd.factorize(df[\"SEXO_PACIENTE\"])\n",
        "df[\"SEXO_PACIENTE\"]=cod_sex+1\n",
        "\n",
        "cod_Diag,map_Diag=pd.factorize(df[\"DIAGNOSTICO\"])\n",
        "df[\"DIAGNOSTICO\"]=cod_Diag+1\n",
        "\n",
        "cod_Serv,map_Serv=pd.factorize(df[\"SERVICIO_HOSPITALARIO\"])\n",
        "df[\"SERVICIO_HOSPITALARIO\"]=cod_Serv+1\n",
        "\n",
        "cod_Pro1,map_Pro1=pd.factorize(df[\"PROCEDIMIENTO_1\"])\n",
        "df[\"PROCEDIMIENTO_1\"]=cod_Pro1+1\n",
        "\n",
        "df.loc[\n",
        "    (df[\"UNIDADES_1\"] == \"mmol/lt\") & (df[\"PROCEDIMIENTO_1\"] == 1),\n",
        "    \"RESULTADO_1\"\n",
        "] *= 18\n",
        "\n",
        "df.loc[\n",
        "    (df[\"UNIDADES_1\"] == \"mmol/lt\") & (df[\"PROCEDIMIENTO_1\"] == 2),\n",
        "    \"RESULTADO_1\"\n",
        "] *= 88.57\n",
        "\n",
        "cod_Pro1,map_Pro1=pd.factorize(df[\"PROCEDIMIENTO_2\"])\n",
        "df[\"PROCEDIMIENTO_2\"]=cod_Pro1+1\n",
        "\n",
        "df.loc[\n",
        "    (df[\"UNIDADES_2\"] == \"mmol/lt\") & (df[\"PROCEDIMIENTO_2\"] == 1),\n",
        "    \"RESULTADO_2\"\n",
        "] *= 18\n",
        "\n",
        "df.loc[\n",
        "    (df[\"UNIDADES_2\"] == \"mmol/lt\") & (df[\"PROCEDIMIENTO_2\"] == 2),\n",
        "    \"RESULTADO_2\"\n",
        "] *= 88.57\n",
        "\n",
        "\n",
        "df = df.drop(df.columns[[0, 4, 5,6,7,10,11,12,14,16,17,18,19,22,23,26,27]], axis=1)\n",
        "\n",
        "\n",
        "df.to_excel(\"resultado.xlsx\",index=False)#Exportacion de dataset preprocesado en .xlsx\n"
      ],
      "metadata": {
        "id": "geyN3L-tCdgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mapas de categorizacion numerica a cada columna de informacion\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Dep)}\n",
        "print(mapeo)\n",
        "\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Prov)}\n",
        "print(mapeo)\n",
        "\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Dist)}\n",
        "print(mapeo)\n",
        "\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Sex)}\n",
        "print(mapeo)\n",
        "\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Diag)}\n",
        "print(mapeo)\n",
        "\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Serv)}\n",
        "print(mapeo)\n",
        "\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Pro1)}\n",
        "print(mapeo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIU2qrD_Cgeh",
        "outputId": "4bc18ba7-9e00-4b94-bd79-d71ec31ed3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'LIMA': 1, 'LA LIBERTAD': 2, 'CAJAMARCA': 3, 'CALLAO': 4, 'AREQUIPA': 5, 'ANCASH': 6, 'HUANUCO': 7, 'SAN MARTIN': 8, 'TUMBES': 9, 'JUNIN': 10, 'LORETO': 11, 'AMAZONAS': 12, 'PIURA': 13, 'ICA': 14, 'TACNA': 15, 'AYACUCHO': 16, 'APURIMAC': 17, 'LAMBAYEQUE': 18, 'MOQUEGUA': 19, 'PUNO': 20, 'CUSCO': 21, 'PASCO': 22, 'MADRE DE DIOS': 23, 'HUANCAVELICA': 24}\n",
            "{'LIMA': 1, 'TRUJILLO': 2, 'JAEN': 3, 'CALLAO': 4, 'AREQUIPA': 5, 'SANTA': 6, 'HUANUCO': 7, 'SAN MARTIN': 8, 'TUMBES': 9, 'HUANCAYO': 10, 'MAYNAS': 11, 'CHACHAPOYAS': 12, 'HUAURA': 13, 'PIURA': 14, 'CAJAMARCA': 15, 'ICA': 16, 'TACNA': 17, 'HUARAL': 18, 'HUAMANGA': 19, 'ABANCAY': 20, 'CHICLAYO': 21, 'LAMBAYEQUE': 22, 'MOYOBAMBA': 23, 'HUARAZ': 24, 'ANDAHUAYLAS': 25, 'MARISCAL NIETO': 26, 'SAN ROMAN': 27, 'CUSCO': 28, 'CHANCHAMAYO': 29, 'CASMA': 30, 'CANETE': 31, 'MARISCAL CACERES': 32, 'FERRENAFE': 33, 'ILO': 34, 'PUNO': 35, 'LORETO': 36, 'PASCO': 37, 'OXAPAMPA': 38, 'TALARA': 39, 'ISLAY': 40, 'CHEPEN': 41, 'CONCEPCION': 42, 'CHINCHA': 43, 'PACASMAYO': 44, 'SULLANA': 45, 'ALTO AMAZONAS': 46, 'SAN IGNACIO': 47, 'POMABAMBA': 48, 'UTCUBAMBA': 49, 'PISCO': 50, 'VIRU': 51, 'ASCOPE': 52, 'CASTILLA': 53, 'HUAYLAS': 54, 'CAMANA': 55, 'TAMBOPATA': 56, 'HUANCAVELICA': 57, 'CUTERVO': 58, 'YAULI': 59, 'RIOJA': 60, 'BAGUA': 61, 'CHUPACA': 62, 'CHOTA': 63, 'CANCHIS': 64, 'BARRANCA': 65, 'TARMA': 66, 'AYMARAES': 67, 'LA CONVENCION': 68, 'JAUJA': 69, 'SECHURA': 70, 'JORGE BASADRE': 71, 'MORROPON': 72, 'BELLAVISTA': 73, 'YUNGAY': 74, 'ACOMAYO': 75, 'GRAN CHIMU': 76, 'HUARMEY': 77, 'SATIPO': 78, 'LA UNION': 79, 'HUALGAYOC': 80, 'LAMPA': 81, 'CHINCHEROS': 82, 'LAMAS': 83, 'SANCHEZ CARRION': 84, 'CALCA': 85, 'URUBAMBA': 86, 'BONGARA': 87, 'LUYA': 88, 'TARATA': 89, 'MANU': 90, 'CARHUAZ': 91, 'HUALLAGA': 92, 'PAUCARTAMBO': 93, 'HUARI': 94, 'CAYLLOMA': 95, 'CHUCUITO': 96, 'ESPINAR': 97, 'CONDESUYOS': 98}\n",
            "{'MIRAFLORES': 1, 'VICTOR LARCO HERRERA': 2, 'JAEN': 3, 'SAN JUAN DE LURIGANCHO': 4, 'VENTANILLA': 5, 'SAN LUIS': 6, 'YANAHUARA': 7, 'TRUJILLO': 8, 'CHIMBOTE': 9, 'SANTIAGO DE SURCO': 10, 'LA MOLINA': 11, 'SURQUILLO': 12, 'LAREDO': 13, 'AMARILIS': 14, 'TARAPOTO': 15, 'TUMBES': 16, 'LA ESPERANZA': 17, 'COMAS': 18, 'EL TAMBO': 19, 'LOS OLIVOS': 20, 'VILLA EL SALVADOR': 21, 'SAN JUAN BAUTISTA': 22, 'CHACHAPOYAS': 23, 'SAYAN': 24, 'LIMA': 25, 'PIURA': 26, 'SAN ISIDRO': 27, 'AREQUIPA': 28, 'CAJAMARCA': 29, 'ICA': 30, 'CALLAO': 31, 'INDEPENDENCIA': 32, 'PUENTE PIEDRA': 33, 'CHORRILLOS': 34, 'HUANCAYO': 35, 'TACNA': 36, 'CHANCAY': 37, 'SANTIAGO': 38, 'HUANUCO': 39, 'RIMAC': 40, 'CARABAYLLO': 41, 'AYACUCHO': 42, 'HUARAL': 43, 'LA VICTORIA': 44, 'ABANCAY': 45, 'SAN MIGUEL': 46, 'CALANA': 47, 'CHICLAYO': 48, 'LAMBAYEQUE': 49, 'MOYOBAMBA': 50, 'PAUCARPATA': 51, 'HUARAZ': 52, 'ANDAHUAYLAS': 53, 'SOCABAYA': 54, 'ALTO SELVA ALEGRE': 55, 'BELLAVISTA': 56, 'LINCE': 57, 'MOQUEGUA': 58, 'SAN JUAN DE MIRAFLORES': 59, 'IQUITOS': 60, 'JULIACA': 61, 'CUSCO': 62, 'CHANCHAMAYO': 63, 'CASMA': 64, 'SAN VICENTE DE CANETE': 65, 'JUANJUI': 66, 'LURIGANCHO': 67, 'FERRENAFE': 68, 'ILO': 69, 'PUNO': 70, 'JOSE LEONARDO ORTIZ': 71, 'MORALES': 72, 'EL AGUSTINO': 73, 'SANTA ANITA': 74, 'HUACHO': 75, 'MOCHE': 76, 'FLORENCIA DE MORA': 77, 'JESUS MARIA': 78, 'NAUTA': 79, 'CHAUPIMARCA': 80, 'OXAPAMPA': 81, 'PARINAS': 82, 'SAN SEBASTIAN': 83, 'MOLLENDO': 84, 'CHEPEN': 85, 'CONCEPCION': 86, 'CHINCHA ALTA': 87, 'LURIN': 88, 'SAMEGUA': 89, 'PATAPO': 90, 'PACASMAYO': 91, 'SULLANA': 92, 'YURIMAGUAS': 93, 'SAN IGNACIO': 94, 'POMABAMBA': 95, 'BAGUA GRANDE': 96, 'PISCO': 97, 'VIRU': 98, 'CHOCOPE': 99, 'APLAO': 100, 'CARAZ': 101, 'EL PORVENIR': 102, 'CASTILLA': 103, 'SAMUEL PASTOR': 104, 'JAYANCA': 105, 'CHILCA': 106, 'ETEN': 107, 'TAMBOPATA': 108, 'PIMENTEL': 109, 'ASCENSION': 110, 'ASCOPE': 111, 'CUTERVO': 112, 'SAN PEDRO DE LLOC': 113, 'LA OROYA': 114, 'RIOJA': 115, 'PUNCHANA': 116, 'SAN JOSE': 117, 'LA PECA': 118, 'LA BREA': 119, 'CHUPACA': 120, 'CHOTA': 121, 'OYOTUN': 122, 'JACOBO HUNTER': 123, 'CATACAOS': 124, 'SICUANI': 125, 'MOTUPE': 126, 'NEPENA': 127, 'CASA GRANDE': 128, 'CHAO': 129, 'MALA': 130, 'PARAMONGA': 131, 'TARMA': 132, 'CHALHUANCA': 133, 'COISHCO': 134, 'SANTA ANA': 135, 'LA JOYA': 136, 'TUCUME': 137, 'JAUJA': 138, 'SECHURA': 139, 'YURA': 140, 'LOCUMBA': 141, 'CHULUCANAS': 142, 'YUNGAY': 143, 'ACOMAYO': 144, 'TUPAC AMARU INCA': 145, 'IGNACIO ESCUDERO': 146, 'SANTIAGO DE CAO': 147, 'CASCAS': 148, 'HUARMEY': 149, 'SATIPO': 150, 'TAMBO GRANDE': 151, 'COTAHUASI': 152, 'LA UNION': 153, 'SAN CLEMENTE': 154, 'HUALGAYOC': 155, 'LAMPA': 156, 'ISLAY': 157, 'OLMOS': 158, 'YANACANCHA': 159, 'PUCARA': 160, 'HUANCHACO': 161, 'VITOR': 162, 'JEQUETEPEQUE': 163, 'NUEVA CAJAMARCA': 164, 'RAZURI': 165, 'URACA': 166, 'CHINCHEROS': 167, 'SALAVERRY': 168, 'LAMAS': 169, 'HUAMACHUCO': 170, 'TAMBO DE MORA': 171, 'CALCA': 172, 'URUBAMBA': 173, 'LAGUNAS': 174, 'PAIJAN': 175, 'HUARIACA': 176, 'JAZAN': 177, 'VILLA RICA': 178, 'LAMUD': 179, 'OCALLI': 180, 'TARATA': 181, 'PICHANAQUI': 182, 'MANU': 183, 'CARHUAZ': 184, 'EL ALTO': 185, 'SAPOSOA': 186, 'ITE': 187, 'GUADALUPE': 188, 'PAUCARTAMBO': 189, 'LA TINGUINA': 190, 'HUARI': 191, 'CHIVAY': 192, 'DESAGUADERO': 193, 'ESPINAR': 194, 'CURAHUASI': 195, 'CHUQUIBAMBA': 196, 'ILABAYA': 197}\n",
            "{'FEMENINO': 1, 'MASCULINO': 2}\n",
            "{'HIPOTIROIDISMO, NO ESPECIFICADO': 1, 'SOBREPESO': 2, 'OBESIDAD, NO ESPECIFICADA': 3, 'OBESIDAD DEBIDA A EXCESO DE CALORIAS': 4, 'CONSULTA PARA INSTRUCCION Y VIGILANCIA DE LA DIETA': 5, 'OTROS TIPOS DE OBESIDAD': 6, 'OBESIDAD EXTREMA CON HIPOVENTILACION ALVEOLAR': 7, 'OTROS TRASTORNOS DE LA GLANDULA HIPOFISIS': 8, 'OBESIDAD INDUCIDA POR DROGAS': 9}\n",
            "{'ENDOCRINOLOGIA': 1, 'PEDIATRIA': 2, 'MEDICINA INTERNA': 3, 'CIRUGIA GENERAL': 4, 'MEDICINA GENERAL': 5, 'MEDICINA FAMILIAR Y COMUNITARIA': 6, 'CARDIOLOGIA': 7, 'GERIATRIA': 8, 'MEDICO DE PERSONAL': 9, 'NEUROLOGIA PEDIATRICA': 10, 'MEDICINA OCUPACIONAL Y DEL MEDIO AMBIENTE': 11, 'ESPECIALIDADES PEDIATRICAS': 12, 'ENDOCRINOLOGIA PEDIATRICA': 13, 'MEDICINA COMPLEMENTARIA': 14, 'GASTROENTEROLOGIA': 15, 'NEFROLOGIA': 16, 'ENFERMEDADES INFECCIOSAS Y TROPICALES': 17, 'NEUMOLOGIA': 18, 'OFTALMOLOGIA': 19, 'GINECOLOGIA Y OBSTETRICIA': 20, 'DERMATOLOGIA': 21, 'GINECOLOGIA': 22, 'NEUROLOGIA': 23, 'REUMATOLOGIA': 24, 'HEMATOLOGIA CLINICA': 25, 'OBSTETRICIA DE ALTO RIESGO': 26, 'PSIQUIATRIA': 27, 'UROLOGIA GENERAL': 28, 'ONCOLOGIA MEDICA': 29, 'CIRUGIA PEDIATRICA': 30, 'OBSTETRICIA': 31, 'ANESTESIA, ANALGESIA Y REANIMACION': 32, 'CIRUGIA DE TORAX Y CARDIOVASCULAR': 33, 'NEUROCIRUGIA': 34, 'HOSPITAL DE DIA': 35, 'MEDICINA NUCLEAR': 36, 'ORTOPEDIA Y TRAUMATOLOGIA': 37, 'CITOPATOLOGIA Y CITOGENETICA': 38, 'PSIQUIATRIA-INFANTO-JUVENIL': 39, 'TRASPLANTE DE HIGADO': 40, 'MEDICINA FISICA Y REHABILITACION': 41, 'CARDIOLOGIA INVASIVA': 42, 'MEDICINA DEL ADOLESCENTE': 43}\n",
            "{'TRIGLICERIDOS': 1, 'DOSAJE DE GLUCOSA EN SANGRE, CUANTITATIVO (EXCEPTO CINTA REACTIVA)': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exportacion de archivo .xlsx a un arreglo numpy\n",
        "df = pd.read_excel(\"resultado.xlsx\")\n",
        "\n",
        "y = df[\"DIAGNOSTICO\"]\n",
        "X = df.drop(columns=[\"DIAGNOSTICO\"])\n",
        "\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "#Cambio Oscar\n",
        "y = y.astype('int32') - 1\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Y0JdilNDHccb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aleatorizacion y distribucion del data set\n",
        "\n",
        "#Pesos para dataset train/val/test\n",
        "train_peso = 0.65\n",
        "val_peso   = 0.20\n",
        "test_peso  = 0.15\n",
        "\n",
        "total_size = len(X)\n",
        "train_size = int(train_peso * total_size)\n",
        "val_size   = int(val_peso * total_size)\n",
        "test_size  = total_size - train_size - val_size\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "dataset = dataset.shuffle(len(X), seed=42)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "rest_dataset  = dataset.skip(train_size)\n",
        "\n",
        "val_dataset   = rest_dataset.take(val_size)\n",
        "test_dataset  = rest_dataset.skip(val_size)\n",
        "\n",
        "#Division de dataset por lotes\n",
        "\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE) #Lotes del dataset para train\n",
        "val_dataset   = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE) #Lotes del dataset para val\n",
        "test_dataset  = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE) #Lotes del dataset para test\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Up9BtVSmMTwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "input_dim = X.shape[1]\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "print(\"Número de características:\", input_dim)\n",
        "print(\"Número de clases:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4_mRKy68E_C",
        "outputId": "5c2d3f60-8813-42a5-910b-894122e645f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de características: 10\n",
            "Número de clases: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Diagnósticos originales:\")\n",
        "for i, diag in enumerate(map_Diag):\n",
        "    print(f\"{i} → {diag}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fbm00O4HDFe",
        "outputId": "cd89e9c5-9dd2-4453-adb2-6377ed62ddde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagnósticos originales:\n",
            "0 → HIPOTIROIDISMO, NO ESPECIFICADO\n",
            "1 → SOBREPESO\n",
            "2 → OBESIDAD, NO ESPECIFICADA\n",
            "3 → OBESIDAD DEBIDA A EXCESO DE CALORIAS\n",
            "4 → CONSULTA PARA INSTRUCCION Y VIGILANCIA DE LA DIETA\n",
            "5 → OTROS TIPOS DE OBESIDAD\n",
            "6 → OBESIDAD EXTREMA CON HIPOVENTILACION ALVEOLAR\n",
            "7 → OTROS TRASTORNOS DE LA GLANDULA HIPOFISIS\n",
            "8 → OBESIDAD INDUCIDA POR DROGAS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "\n",
        "input_dim = 10\n",
        "num_classes = 9\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', kernel_initializer=HeNormal(), input_shape=(input_dim,)),\n",
        "    Dense(64, activation='relu', kernel_initializer=HeNormal()),\n",
        "    Dense(32, activation='relu', kernel_initializer=HeNormal()),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "Z2XArINzFHCp",
        "outputId": "ae5999d0-f89d-4fe8-c2be-6ba20f08f0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m297\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">297</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,041\u001b[0m (47.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,041</span> (47.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,041\u001b[0m (47.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,041</span> (47.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=60\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_0IDKq3GZj9",
        "outputId": "d2d99e68-f55e-427a-8e21-edd6a3c73d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5048 - loss: 1.2692 - val_accuracy: 0.5458 - val_loss: 1.0995\n",
            "Epoch 2/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5416 - loss: 1.1141 - val_accuracy: 0.5461 - val_loss: 1.0996\n",
            "Epoch 3/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5492 - loss: 1.1000 - val_accuracy: 0.5543 - val_loss: 1.0892\n",
            "Epoch 4/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5587 - loss: 1.0828 - val_accuracy: 0.5640 - val_loss: 1.0732\n",
            "Epoch 5/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5635 - loss: 1.0753 - val_accuracy: 0.5601 - val_loss: 1.0753\n",
            "Epoch 6/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5673 - loss: 1.0611 - val_accuracy: 0.5772 - val_loss: 1.0449\n",
            "Epoch 7/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5693 - loss: 1.0576 - val_accuracy: 0.5690 - val_loss: 1.0568\n",
            "Epoch 8/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5700 - loss: 1.0609 - val_accuracy: 0.5784 - val_loss: 1.0429\n",
            "Epoch 9/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5771 - loss: 1.0422 - val_accuracy: 0.5798 - val_loss: 1.0363\n",
            "Epoch 10/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5772 - loss: 1.0417 - val_accuracy: 0.5771 - val_loss: 1.0336\n",
            "Epoch 11/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5780 - loss: 1.0328 - val_accuracy: 0.5866 - val_loss: 1.0191\n",
            "Epoch 12/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5852 - loss: 1.0281 - val_accuracy: 0.5774 - val_loss: 1.0272\n",
            "Epoch 13/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5851 - loss: 1.0287 - val_accuracy: 0.5896 - val_loss: 1.0078\n",
            "Epoch 14/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 1.0241 - val_accuracy: 0.5811 - val_loss: 1.0257\n",
            "Epoch 15/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5834 - loss: 1.0201 - val_accuracy: 0.5914 - val_loss: 1.0071\n",
            "Epoch 16/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5865 - loss: 1.0222 - val_accuracy: 0.5845 - val_loss: 1.0100\n",
            "Epoch 17/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5820 - loss: 1.0225 - val_accuracy: 0.5924 - val_loss: 1.0050\n",
            "Epoch 18/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5851 - loss: 1.0150 - val_accuracy: 0.5905 - val_loss: 1.0014\n",
            "Epoch 19/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5949 - loss: 1.0042 - val_accuracy: 0.5981 - val_loss: 0.9934\n",
            "Epoch 20/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5920 - loss: 1.0018 - val_accuracy: 0.5929 - val_loss: 0.9902\n",
            "Epoch 21/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5934 - loss: 0.9981 - val_accuracy: 0.5992 - val_loss: 0.9817\n",
            "Epoch 22/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5949 - loss: 1.0002 - val_accuracy: 0.5960 - val_loss: 0.9945\n",
            "Epoch 23/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5908 - loss: 1.0066 - val_accuracy: 0.5971 - val_loss: 0.9966\n",
            "Epoch 24/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5974 - loss: 0.9938 - val_accuracy: 0.5973 - val_loss: 0.9826\n",
            "Epoch 25/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5937 - loss: 0.9902 - val_accuracy: 0.6006 - val_loss: 0.9779\n",
            "Epoch 26/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5925 - loss: 0.9944 - val_accuracy: 0.6015 - val_loss: 0.9777\n",
            "Epoch 27/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5940 - loss: 0.9859 - val_accuracy: 0.5986 - val_loss: 0.9722\n",
            "Epoch 28/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.9782 - val_accuracy: 0.5961 - val_loss: 0.9774\n",
            "Epoch 29/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6002 - loss: 0.9771 - val_accuracy: 0.6011 - val_loss: 0.9783\n",
            "Epoch 30/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.9800 - val_accuracy: 0.6015 - val_loss: 0.9710\n",
            "Epoch 31/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 0.9728 - val_accuracy: 0.6015 - val_loss: 0.9777\n",
            "Epoch 32/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5992 - loss: 0.9779 - val_accuracy: 0.6014 - val_loss: 0.9585\n",
            "Epoch 33/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6019 - loss: 0.9677 - val_accuracy: 0.6082 - val_loss: 0.9610\n",
            "Epoch 34/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5987 - loss: 0.9740 - val_accuracy: 0.6030 - val_loss: 0.9668\n",
            "Epoch 35/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6087 - loss: 0.9559 - val_accuracy: 0.6037 - val_loss: 0.9606\n",
            "Epoch 36/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6081 - loss: 0.9605 - val_accuracy: 0.6098 - val_loss: 0.9568\n",
            "Epoch 37/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6043 - loss: 0.9676 - val_accuracy: 0.6123 - val_loss: 0.9509\n",
            "Epoch 38/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6041 - loss: 0.9611 - val_accuracy: 0.6138 - val_loss: 0.9419\n",
            "Epoch 39/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6081 - loss: 0.9552 - val_accuracy: 0.6008 - val_loss: 0.9601\n",
            "Epoch 40/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6047 - loss: 0.9604 - val_accuracy: 0.5988 - val_loss: 0.9626\n",
            "Epoch 41/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6094 - loss: 0.9561 - val_accuracy: 0.6073 - val_loss: 0.9593\n",
            "Epoch 42/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6131 - loss: 0.9498 - val_accuracy: 0.6058 - val_loss: 0.9552\n",
            "Epoch 43/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6085 - loss: 0.9548 - val_accuracy: 0.6065 - val_loss: 0.9563\n",
            "Epoch 44/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6073 - loss: 0.9505 - val_accuracy: 0.6137 - val_loss: 0.9436\n",
            "Epoch 45/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6109 - loss: 0.9496 - val_accuracy: 0.6167 - val_loss: 0.9283\n",
            "Epoch 46/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6072 - loss: 0.9568 - val_accuracy: 0.6120 - val_loss: 0.9425\n",
            "Epoch 47/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6108 - loss: 0.9483 - val_accuracy: 0.6168 - val_loss: 0.9385\n",
            "Epoch 48/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6079 - loss: 0.9517 - val_accuracy: 0.6157 - val_loss: 0.9438\n",
            "Epoch 49/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6073 - loss: 0.9479 - val_accuracy: 0.6079 - val_loss: 0.9470\n",
            "Epoch 50/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6111 - loss: 0.9498 - val_accuracy: 0.6174 - val_loss: 0.9302\n",
            "Epoch 51/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6140 - loss: 0.9459 - val_accuracy: 0.6131 - val_loss: 0.9427\n",
            "Epoch 52/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6122 - loss: 0.9405 - val_accuracy: 0.6172 - val_loss: 0.9377\n",
            "Epoch 53/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6106 - loss: 0.9433 - val_accuracy: 0.6118 - val_loss: 0.9389\n",
            "Epoch 54/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6071 - loss: 0.9464 - val_accuracy: 0.6132 - val_loss: 0.9391\n",
            "Epoch 55/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6109 - loss: 0.9489 - val_accuracy: 0.6087 - val_loss: 0.9392\n",
            "Epoch 56/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6083 - loss: 0.9432 - val_accuracy: 0.6084 - val_loss: 0.9484\n",
            "Epoch 57/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6110 - loss: 0.9402 - val_accuracy: 0.6171 - val_loss: 0.9297\n",
            "Epoch 58/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6083 - loss: 0.9493 - val_accuracy: 0.6127 - val_loss: 0.9377\n",
            "Epoch 59/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6112 - loss: 0.9395 - val_accuracy: 0.6145 - val_loss: 0.9289\n",
            "Epoch 60/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6143 - loss: 0.9403 - val_accuracy: 0.6130 - val_loss: 0.9402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Bésqueda de hiperparametros\n",
        "def crear_modelo(units1, units2, units3=None, lr=0.001):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(units1, activation='relu',\n",
        "                                    kernel_initializer=HeNormal(),\n",
        "                                    input_shape=(input_dim,)))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(units2, activation='relu',\n",
        "                                    kernel_initializer=HeNormal()))\n",
        "\n",
        "    if units3:\n",
        "        model.add(tf.keras.layers.Dense(units3, activation='relu',\n",
        "                                        kernel_initializer=HeNormal()))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "1XoyM4yPpSEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"===== MODELO A =====\")\n",
        "model_A = crear_modelo(64, 32, lr=0.001)\n",
        "history_A = model_A.fit(train_dataset, validation_data=val_dataset, epochs=60)\n",
        "\n",
        "print(\"\\n===== MODELO B =====\")\n",
        "model_B = crear_modelo(128, 64, 32, lr=0.001)\n",
        "history_B = model_B.fit(train_dataset, validation_data=val_dataset, epochs=60)\n",
        "\n",
        "print(\"\\n===== MODELO C =====\")\n",
        "model_C = crear_modelo(256, 128, 64, lr=0.0005)\n",
        "history_C = model_C.fit(train_dataset, validation_data=val_dataset, epochs=60)\n",
        "\n",
        "# Cambio de batch size\n",
        "train_dataset_64 = train_dataset.unbatch().batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset_64 = val_dataset.unbatch().batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"\\n===== MODELO D =====\")\n",
        "model_D = crear_modelo(256, 128, 64, lr=0.0005)\n",
        "history_D = model_D.fit(train_dataset_64,\n",
        "                        validation_data=val_dataset_64,\n",
        "                        epochs=80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLJ_Z1iFruen",
        "outputId": "0fbc3f95-8208-4bb3-9fcf-e3e6e5e08985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== MODELO A =====\n",
            "Epoch 1/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4862 - loss: 1.3056 - val_accuracy: 0.5353 - val_loss: 1.1275\n",
            "Epoch 2/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5453 - loss: 1.1177 - val_accuracy: 0.5529 - val_loss: 1.1092\n",
            "Epoch 3/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5494 - loss: 1.1078 - val_accuracy: 0.5492 - val_loss: 1.1058\n",
            "Epoch 4/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5480 - loss: 1.0974 - val_accuracy: 0.5548 - val_loss: 1.0913\n",
            "Epoch 5/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5540 - loss: 1.0958 - val_accuracy: 0.5636 - val_loss: 1.0816\n",
            "Epoch 6/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5598 - loss: 1.0865 - val_accuracy: 0.5564 - val_loss: 1.0825\n",
            "Epoch 7/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5644 - loss: 1.0725 - val_accuracy: 0.5700 - val_loss: 1.0546\n",
            "Epoch 8/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5653 - loss: 1.0733 - val_accuracy: 0.5739 - val_loss: 1.0583\n",
            "Epoch 9/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5646 - loss: 1.0669 - val_accuracy: 0.5642 - val_loss: 1.0652\n",
            "Epoch 10/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5674 - loss: 1.0631 - val_accuracy: 0.5695 - val_loss: 1.0583\n",
            "Epoch 11/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5702 - loss: 1.0654 - val_accuracy: 0.5737 - val_loss: 1.0538\n",
            "Epoch 12/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5754 - loss: 1.0488 - val_accuracy: 0.5754 - val_loss: 1.0458\n",
            "Epoch 13/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5740 - loss: 1.0505 - val_accuracy: 0.5765 - val_loss: 1.0514\n",
            "Epoch 14/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5748 - loss: 1.0469 - val_accuracy: 0.5805 - val_loss: 1.0411\n",
            "Epoch 15/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5805 - loss: 1.0408 - val_accuracy: 0.5777 - val_loss: 1.0319\n",
            "Epoch 16/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5762 - loss: 1.0468 - val_accuracy: 0.5793 - val_loss: 1.0396\n",
            "Epoch 17/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5803 - loss: 1.0451 - val_accuracy: 0.5757 - val_loss: 1.0476\n",
            "Epoch 18/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5784 - loss: 1.0427 - val_accuracy: 0.5770 - val_loss: 1.0453\n",
            "Epoch 19/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5806 - loss: 1.0411 - val_accuracy: 0.5833 - val_loss: 1.0380\n",
            "Epoch 20/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5773 - loss: 1.0434 - val_accuracy: 0.5851 - val_loss: 1.0315\n",
            "Epoch 21/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5818 - loss: 1.0358 - val_accuracy: 0.5868 - val_loss: 1.0311\n",
            "Epoch 22/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5733 - loss: 1.0500 - val_accuracy: 0.5776 - val_loss: 1.0294\n",
            "Epoch 23/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5834 - loss: 1.0243 - val_accuracy: 0.5813 - val_loss: 1.0277\n",
            "Epoch 24/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5841 - loss: 1.0301 - val_accuracy: 0.5822 - val_loss: 1.0374\n",
            "Epoch 25/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5840 - loss: 1.0377 - val_accuracy: 0.5834 - val_loss: 1.0337\n",
            "Epoch 26/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5848 - loss: 1.0295 - val_accuracy: 0.5874 - val_loss: 1.0212\n",
            "Epoch 27/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5877 - loss: 1.0220 - val_accuracy: 0.5763 - val_loss: 1.0373\n",
            "Epoch 28/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 1.0214 - val_accuracy: 0.5859 - val_loss: 1.0191\n",
            "Epoch 29/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5825 - loss: 1.0280 - val_accuracy: 0.5906 - val_loss: 1.0142\n",
            "Epoch 30/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5843 - loss: 1.0269 - val_accuracy: 0.5914 - val_loss: 1.0075\n",
            "Epoch 31/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5830 - loss: 1.0251 - val_accuracy: 0.5899 - val_loss: 1.0149\n",
            "Epoch 32/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5864 - loss: 1.0201 - val_accuracy: 0.5783 - val_loss: 1.0252\n",
            "Epoch 33/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5870 - loss: 1.0146 - val_accuracy: 0.5831 - val_loss: 1.0235\n",
            "Epoch 34/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 1.0122 - val_accuracy: 0.5928 - val_loss: 1.0042\n",
            "Epoch 35/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5862 - loss: 1.0162 - val_accuracy: 0.5837 - val_loss: 1.0189\n",
            "Epoch 36/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5842 - loss: 1.0206 - val_accuracy: 0.5856 - val_loss: 1.0158\n",
            "Epoch 37/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 1.0132 - val_accuracy: 0.5903 - val_loss: 1.0071\n",
            "Epoch 38/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 1.0144 - val_accuracy: 0.5946 - val_loss: 0.9994\n",
            "Epoch 39/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5895 - loss: 1.0105 - val_accuracy: 0.5916 - val_loss: 1.0042\n",
            "Epoch 40/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5877 - loss: 1.0139 - val_accuracy: 0.5943 - val_loss: 1.0073\n",
            "Epoch 41/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 1.0094 - val_accuracy: 0.5940 - val_loss: 0.9993\n",
            "Epoch 42/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5883 - loss: 1.0111 - val_accuracy: 0.5910 - val_loss: 1.0123\n",
            "Epoch 43/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5960 - loss: 1.0055 - val_accuracy: 0.5929 - val_loss: 0.9992\n",
            "Epoch 44/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5955 - loss: 1.0022 - val_accuracy: 0.5888 - val_loss: 1.0215\n",
            "Epoch 45/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5917 - loss: 1.0070 - val_accuracy: 0.5931 - val_loss: 1.0082\n",
            "Epoch 46/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5951 - loss: 1.0057 - val_accuracy: 0.6008 - val_loss: 0.9956\n",
            "Epoch 47/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 0.9963 - val_accuracy: 0.5964 - val_loss: 1.0063\n",
            "Epoch 48/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5878 - loss: 1.0089 - val_accuracy: 0.5964 - val_loss: 0.9976\n",
            "Epoch 49/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: 1.0013 - val_accuracy: 0.5955 - val_loss: 0.9965\n",
            "Epoch 50/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5928 - loss: 1.0082 - val_accuracy: 0.5971 - val_loss: 0.9940\n",
            "Epoch 51/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5951 - loss: 0.9983 - val_accuracy: 0.5931 - val_loss: 1.0053\n",
            "Epoch 52/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5933 - loss: 1.0008 - val_accuracy: 0.5968 - val_loss: 0.9895\n",
            "Epoch 53/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5939 - loss: 1.0048 - val_accuracy: 0.5929 - val_loss: 1.0026\n",
            "Epoch 54/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 0.9932 - val_accuracy: 0.5937 - val_loss: 0.9979\n",
            "Epoch 55/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5915 - loss: 1.0059 - val_accuracy: 0.5996 - val_loss: 0.9823\n",
            "Epoch 56/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5985 - loss: 0.9888 - val_accuracy: 0.5938 - val_loss: 0.9940\n",
            "Epoch 57/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5952 - loss: 1.0053 - val_accuracy: 0.5921 - val_loss: 0.9939\n",
            "Epoch 58/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5932 - loss: 0.9984 - val_accuracy: 0.6022 - val_loss: 0.9899\n",
            "Epoch 59/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5967 - loss: 0.9937 - val_accuracy: 0.5964 - val_loss: 0.9959\n",
            "Epoch 60/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5960 - loss: 0.9934 - val_accuracy: 0.5992 - val_loss: 0.9871\n",
            "\n",
            "===== MODELO B =====\n",
            "Epoch 1/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5133 - loss: 1.2238 - val_accuracy: 0.5529 - val_loss: 1.0981\n",
            "Epoch 2/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5403 - loss: 1.1140 - val_accuracy: 0.5566 - val_loss: 1.0922\n",
            "Epoch 3/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5565 - loss: 1.0989 - val_accuracy: 0.5645 - val_loss: 1.0857\n",
            "Epoch 4/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5569 - loss: 1.0817 - val_accuracy: 0.5611 - val_loss: 1.0778\n",
            "Epoch 5/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5615 - loss: 1.0782 - val_accuracy: 0.5682 - val_loss: 1.0574\n",
            "Epoch 6/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5690 - loss: 1.0623 - val_accuracy: 0.5685 - val_loss: 1.0511\n",
            "Epoch 7/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5686 - loss: 1.0679 - val_accuracy: 0.5838 - val_loss: 1.0314\n",
            "Epoch 8/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5784 - loss: 1.0424 - val_accuracy: 0.5750 - val_loss: 1.0470\n",
            "Epoch 9/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5766 - loss: 1.0443 - val_accuracy: 0.5729 - val_loss: 1.0357\n",
            "Epoch 10/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5788 - loss: 1.0366 - val_accuracy: 0.5762 - val_loss: 1.0433\n",
            "Epoch 11/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5833 - loss: 1.0312 - val_accuracy: 0.5830 - val_loss: 1.0351\n",
            "Epoch 12/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5817 - loss: 1.0328 - val_accuracy: 0.5863 - val_loss: 1.0141\n",
            "Epoch 13/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5869 - loss: 1.0193 - val_accuracy: 0.5813 - val_loss: 1.0240\n",
            "Epoch 14/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5804 - loss: 1.0324 - val_accuracy: 0.5911 - val_loss: 1.0091\n",
            "Epoch 15/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5866 - loss: 1.0147 - val_accuracy: 0.5880 - val_loss: 1.0068\n",
            "Epoch 16/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5878 - loss: 1.0133 - val_accuracy: 0.5890 - val_loss: 1.0130\n",
            "Epoch 17/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5861 - loss: 1.0143 - val_accuracy: 0.5892 - val_loss: 1.0092\n",
            "Epoch 18/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5859 - loss: 1.0083 - val_accuracy: 0.5851 - val_loss: 1.0123\n",
            "Epoch 19/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5837 - loss: 1.0176 - val_accuracy: 0.5921 - val_loss: 1.0005\n",
            "Epoch 20/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5924 - loss: 1.0054 - val_accuracy: 0.5955 - val_loss: 1.0092\n",
            "Epoch 21/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 0.9988 - val_accuracy: 0.5884 - val_loss: 1.0174\n",
            "Epoch 22/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5903 - loss: 1.0114 - val_accuracy: 0.5909 - val_loss: 0.9941\n",
            "Epoch 23/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.9957 - val_accuracy: 0.5938 - val_loss: 0.9872\n",
            "Epoch 24/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5947 - loss: 0.9979 - val_accuracy: 0.5998 - val_loss: 0.9812\n",
            "Epoch 25/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5959 - loss: 0.9883 - val_accuracy: 0.5978 - val_loss: 0.9911\n",
            "Epoch 26/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5901 - loss: 1.0038 - val_accuracy: 0.5893 - val_loss: 0.9974\n",
            "Epoch 27/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5939 - loss: 0.9992 - val_accuracy: 0.6006 - val_loss: 0.9831\n",
            "Epoch 28/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5945 - loss: 0.9895 - val_accuracy: 0.5877 - val_loss: 0.9983\n",
            "Epoch 29/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.9836 - val_accuracy: 0.6055 - val_loss: 0.9700\n",
            "Epoch 30/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5931 - loss: 0.9865 - val_accuracy: 0.6039 - val_loss: 0.9681\n",
            "Epoch 31/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5996 - loss: 0.9857 - val_accuracy: 0.6008 - val_loss: 0.9725\n",
            "Epoch 32/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5994 - loss: 0.9836 - val_accuracy: 0.6100 - val_loss: 0.9604\n",
            "Epoch 33/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5968 - loss: 0.9806 - val_accuracy: 0.6019 - val_loss: 0.9673\n",
            "Epoch 34/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.9686 - val_accuracy: 0.6082 - val_loss: 0.9726\n",
            "Epoch 35/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6001 - loss: 0.9783 - val_accuracy: 0.6001 - val_loss: 0.9784\n",
            "Epoch 36/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6064 - loss: 0.9721 - val_accuracy: 0.6047 - val_loss: 0.9649\n",
            "Epoch 37/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.9701 - val_accuracy: 0.6029 - val_loss: 0.9679\n",
            "Epoch 38/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.9802 - val_accuracy: 0.6066 - val_loss: 0.9686\n",
            "Epoch 39/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5948 - loss: 0.9821 - val_accuracy: 0.6069 - val_loss: 0.9709\n",
            "Epoch 40/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6052 - loss: 0.9627 - val_accuracy: 0.6116 - val_loss: 0.9551\n",
            "Epoch 41/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6011 - loss: 0.9684 - val_accuracy: 0.6014 - val_loss: 0.9682\n",
            "Epoch 42/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6035 - loss: 0.9676 - val_accuracy: 0.6109 - val_loss: 0.9503\n",
            "Epoch 43/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6039 - loss: 0.9611 - val_accuracy: 0.6098 - val_loss: 0.9607\n",
            "Epoch 44/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6043 - loss: 0.9746 - val_accuracy: 0.6087 - val_loss: 0.9641\n",
            "Epoch 45/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6097 - loss: 0.9646 - val_accuracy: 0.5990 - val_loss: 0.9710\n",
            "Epoch 46/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6065 - loss: 0.9639 - val_accuracy: 0.6033 - val_loss: 0.9659\n",
            "Epoch 47/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6028 - loss: 0.9695 - val_accuracy: 0.6080 - val_loss: 0.9597\n",
            "Epoch 48/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6080 - loss: 0.9601 - val_accuracy: 0.6095 - val_loss: 0.9505\n",
            "Epoch 49/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6080 - loss: 0.9590 - val_accuracy: 0.6195 - val_loss: 0.9360\n",
            "Epoch 50/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6114 - loss: 0.9493 - val_accuracy: 0.6091 - val_loss: 0.9519\n",
            "Epoch 51/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6065 - loss: 0.9581 - val_accuracy: 0.6023 - val_loss: 0.9606\n",
            "Epoch 52/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6056 - loss: 0.9568 - val_accuracy: 0.6133 - val_loss: 0.9421\n",
            "Epoch 53/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6066 - loss: 0.9615 - val_accuracy: 0.6084 - val_loss: 0.9448\n",
            "Epoch 54/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6097 - loss: 0.9539 - val_accuracy: 0.6105 - val_loss: 0.9505\n",
            "Epoch 55/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6074 - loss: 0.9526 - val_accuracy: 0.6109 - val_loss: 0.9438\n",
            "Epoch 56/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6131 - loss: 0.9477 - val_accuracy: 0.6113 - val_loss: 0.9429\n",
            "Epoch 57/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6102 - loss: 0.9507 - val_accuracy: 0.6089 - val_loss: 0.9442\n",
            "Epoch 58/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 0.9520 - val_accuracy: 0.6116 - val_loss: 0.9464\n",
            "Epoch 59/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6117 - loss: 0.9522 - val_accuracy: 0.6083 - val_loss: 0.9418\n",
            "Epoch 60/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6071 - loss: 0.9543 - val_accuracy: 0.6158 - val_loss: 0.9413\n",
            "\n",
            "===== MODELO C =====\n",
            "Epoch 1/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5103 - loss: 1.2282 - val_accuracy: 0.5504 - val_loss: 1.1083\n",
            "Epoch 2/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5483 - loss: 1.1033 - val_accuracy: 0.5537 - val_loss: 1.0994\n",
            "Epoch 3/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5583 - loss: 1.0822 - val_accuracy: 0.5574 - val_loss: 1.0919\n",
            "Epoch 4/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5566 - loss: 1.0873 - val_accuracy: 0.5606 - val_loss: 1.0672\n",
            "Epoch 5/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5646 - loss: 1.0762 - val_accuracy: 0.5682 - val_loss: 1.0597\n",
            "Epoch 6/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5680 - loss: 1.0639 - val_accuracy: 0.5753 - val_loss: 1.0356\n",
            "Epoch 7/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.5677 - loss: 1.0682 - val_accuracy: 0.5731 - val_loss: 1.0503\n",
            "Epoch 8/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5765 - loss: 1.0476 - val_accuracy: 0.5716 - val_loss: 1.0554\n",
            "Epoch 9/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5797 - loss: 1.0458 - val_accuracy: 0.5900 - val_loss: 1.0221\n",
            "Epoch 10/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5797 - loss: 1.0361 - val_accuracy: 0.5802 - val_loss: 1.0319\n",
            "Epoch 11/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5822 - loss: 1.0347 - val_accuracy: 0.5833 - val_loss: 1.0260\n",
            "Epoch 12/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5787 - loss: 1.0301 - val_accuracy: 0.5919 - val_loss: 1.0156\n",
            "Epoch 13/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5857 - loss: 1.0235 - val_accuracy: 0.5851 - val_loss: 1.0120\n",
            "Epoch 14/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5854 - loss: 1.0165 - val_accuracy: 0.5933 - val_loss: 1.0061\n",
            "Epoch 15/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.5883 - loss: 1.0162 - val_accuracy: 0.5904 - val_loss: 1.0032\n",
            "Epoch 16/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5841 - loss: 1.0197 - val_accuracy: 0.5894 - val_loss: 1.0007\n",
            "Epoch 17/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5890 - loss: 1.0079 - val_accuracy: 0.5951 - val_loss: 0.9915\n",
            "Epoch 18/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5897 - loss: 1.0024 - val_accuracy: 0.5902 - val_loss: 1.0020\n",
            "Epoch 19/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5931 - loss: 0.9942 - val_accuracy: 0.5905 - val_loss: 1.0026\n",
            "Epoch 20/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5919 - loss: 0.9932 - val_accuracy: 0.5971 - val_loss: 0.9853\n",
            "Epoch 21/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5956 - loss: 0.9947 - val_accuracy: 0.5948 - val_loss: 0.9865\n",
            "Epoch 22/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6007 - loss: 0.9849 - val_accuracy: 0.6018 - val_loss: 0.9690\n",
            "Epoch 23/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5972 - loss: 0.9838 - val_accuracy: 0.5981 - val_loss: 0.9806\n",
            "Epoch 24/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.5967 - loss: 0.9853 - val_accuracy: 0.6056 - val_loss: 0.9640\n",
            "Epoch 25/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 0.9771 - val_accuracy: 0.6035 - val_loss: 0.9706\n",
            "Epoch 26/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5953 - loss: 0.9811 - val_accuracy: 0.5971 - val_loss: 0.9776\n",
            "Epoch 27/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6000 - loss: 0.9742 - val_accuracy: 0.6029 - val_loss: 0.9680\n",
            "Epoch 28/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5982 - loss: 0.9811 - val_accuracy: 0.6051 - val_loss: 0.9639\n",
            "Epoch 29/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6108 - loss: 0.9574 - val_accuracy: 0.5993 - val_loss: 0.9761\n",
            "Epoch 30/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5960 - loss: 0.9758 - val_accuracy: 0.6014 - val_loss: 0.9636\n",
            "Epoch 31/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6016 - loss: 0.9626 - val_accuracy: 0.6082 - val_loss: 0.9579\n",
            "Epoch 32/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6031 - loss: 0.9640 - val_accuracy: 0.6111 - val_loss: 0.9549\n",
            "Epoch 33/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6115 - loss: 0.9553 - val_accuracy: 0.6113 - val_loss: 0.9491\n",
            "Epoch 34/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6056 - loss: 0.9628 - val_accuracy: 0.6101 - val_loss: 0.9509\n",
            "Epoch 35/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6005 - loss: 0.9689 - val_accuracy: 0.6173 - val_loss: 0.9463\n",
            "Epoch 36/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6099 - loss: 0.9486 - val_accuracy: 0.6089 - val_loss: 0.9431\n",
            "Epoch 37/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6081 - loss: 0.9534 - val_accuracy: 0.6040 - val_loss: 0.9580\n",
            "Epoch 38/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6100 - loss: 0.9529 - val_accuracy: 0.6101 - val_loss: 0.9448\n",
            "Epoch 39/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6089 - loss: 0.9498 - val_accuracy: 0.6182 - val_loss: 0.9411\n",
            "Epoch 40/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6061 - loss: 0.9494 - val_accuracy: 0.6178 - val_loss: 0.9343\n",
            "Epoch 41/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6165 - loss: 0.9432 - val_accuracy: 0.6189 - val_loss: 0.9442\n",
            "Epoch 42/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6159 - loss: 0.9386 - val_accuracy: 0.6185 - val_loss: 0.9296\n",
            "Epoch 43/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6169 - loss: 0.9384 - val_accuracy: 0.6138 - val_loss: 0.9375\n",
            "Epoch 44/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6107 - loss: 0.9434 - val_accuracy: 0.6152 - val_loss: 0.9422\n",
            "Epoch 45/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6181 - loss: 0.9350 - val_accuracy: 0.6232 - val_loss: 0.9138\n",
            "Epoch 46/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6106 - loss: 0.9382 - val_accuracy: 0.6129 - val_loss: 0.9288\n",
            "Epoch 47/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6144 - loss: 0.9356 - val_accuracy: 0.6124 - val_loss: 0.9313\n",
            "Epoch 48/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6147 - loss: 0.9330 - val_accuracy: 0.6235 - val_loss: 0.9275\n",
            "Epoch 49/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6187 - loss: 0.9296 - val_accuracy: 0.6207 - val_loss: 0.9157\n",
            "Epoch 50/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6150 - loss: 0.9330 - val_accuracy: 0.6142 - val_loss: 0.9259\n",
            "Epoch 51/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6186 - loss: 0.9248 - val_accuracy: 0.6285 - val_loss: 0.9107\n",
            "Epoch 52/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6254 - loss: 0.9181 - val_accuracy: 0.6204 - val_loss: 0.9137\n",
            "Epoch 53/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6241 - loss: 0.9191 - val_accuracy: 0.6134 - val_loss: 0.9365\n",
            "Epoch 54/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6206 - loss: 0.9250 - val_accuracy: 0.6154 - val_loss: 0.9274\n",
            "Epoch 55/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6251 - loss: 0.9152 - val_accuracy: 0.6186 - val_loss: 0.9198\n",
            "Epoch 56/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6203 - loss: 0.9194 - val_accuracy: 0.6210 - val_loss: 0.9208\n",
            "Epoch 57/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 0.9237 - val_accuracy: 0.6339 - val_loss: 0.8992\n",
            "Epoch 58/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6231 - loss: 0.9189 - val_accuracy: 0.6262 - val_loss: 0.9036\n",
            "Epoch 59/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6273 - loss: 0.9127 - val_accuracy: 0.6294 - val_loss: 0.9086\n",
            "Epoch 60/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6222 - loss: 0.9119 - val_accuracy: 0.6130 - val_loss: 0.9198\n",
            "\n",
            "===== MODELO D =====\n",
            "Epoch 1/80\n",
            "    648/Unknown \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4954 - loss: 1.3189"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4955 - loss: 1.3187 - val_accuracy: 0.5533 - val_loss: 1.1083\n",
            "Epoch 2/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5495 - loss: 1.1069 - val_accuracy: 0.5507 - val_loss: 1.0946\n",
            "Epoch 3/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5561 - loss: 1.0980 - val_accuracy: 0.5562 - val_loss: 1.0903\n",
            "Epoch 4/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5581 - loss: 1.0869 - val_accuracy: 0.5626 - val_loss: 1.0674\n",
            "Epoch 5/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5626 - loss: 1.0795 - val_accuracy: 0.5657 - val_loss: 1.0643\n",
            "Epoch 6/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5676 - loss: 1.0608 - val_accuracy: 0.5661 - val_loss: 1.0571\n",
            "Epoch 7/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5678 - loss: 1.0614 - val_accuracy: 0.5826 - val_loss: 1.0370\n",
            "Epoch 8/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5743 - loss: 1.0533 - val_accuracy: 0.5754 - val_loss: 1.0423\n",
            "Epoch 9/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5745 - loss: 1.0499 - val_accuracy: 0.5721 - val_loss: 1.0448\n",
            "Epoch 10/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5710 - loss: 1.0455 - val_accuracy: 0.5720 - val_loss: 1.0492\n",
            "Epoch 11/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5784 - loss: 1.0410 - val_accuracy: 0.5773 - val_loss: 1.0395\n",
            "Epoch 12/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5761 - loss: 1.0411 - val_accuracy: 0.5747 - val_loss: 1.0358\n",
            "Epoch 13/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5819 - loss: 1.0309 - val_accuracy: 0.5859 - val_loss: 1.0284\n",
            "Epoch 14/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5834 - loss: 1.0292 - val_accuracy: 0.5913 - val_loss: 1.0075\n",
            "Epoch 15/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5810 - loss: 1.0287 - val_accuracy: 0.5845 - val_loss: 1.0143\n",
            "Epoch 16/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5840 - loss: 1.0214 - val_accuracy: 0.5802 - val_loss: 1.0141\n",
            "Epoch 17/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5854 - loss: 1.0158 - val_accuracy: 0.5905 - val_loss: 1.0121\n",
            "Epoch 18/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5887 - loss: 1.0125 - val_accuracy: 0.5957 - val_loss: 0.9975\n",
            "Epoch 19/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5914 - loss: 1.0083 - val_accuracy: 0.5935 - val_loss: 0.9964\n",
            "Epoch 20/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5906 - loss: 1.0063 - val_accuracy: 0.5942 - val_loss: 0.9932\n",
            "Epoch 21/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5929 - loss: 1.0007 - val_accuracy: 0.5999 - val_loss: 0.9985\n",
            "Epoch 22/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5892 - loss: 1.0037 - val_accuracy: 0.5982 - val_loss: 0.9867\n",
            "Epoch 23/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.9861 - val_accuracy: 0.5949 - val_loss: 0.9857\n",
            "Epoch 24/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5956 - loss: 0.9930 - val_accuracy: 0.5953 - val_loss: 0.9867\n",
            "Epoch 25/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5952 - loss: 0.9928 - val_accuracy: 0.5994 - val_loss: 0.9903\n",
            "Epoch 26/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.9837 - val_accuracy: 0.5978 - val_loss: 0.9826\n",
            "Epoch 27/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6009 - loss: 0.9810 - val_accuracy: 0.5941 - val_loss: 0.9786\n",
            "Epoch 28/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.9884 - val_accuracy: 0.5979 - val_loss: 0.9758\n",
            "Epoch 29/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5988 - loss: 0.9803 - val_accuracy: 0.5984 - val_loss: 0.9808\n",
            "Epoch 30/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 0.9829 - val_accuracy: 0.6032 - val_loss: 0.9719\n",
            "Epoch 31/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 0.9715 - val_accuracy: 0.5968 - val_loss: 0.9877\n",
            "Epoch 32/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6102 - loss: 0.9619 - val_accuracy: 0.6040 - val_loss: 0.9655\n",
            "Epoch 33/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6007 - loss: 0.9741 - val_accuracy: 0.6062 - val_loss: 0.9655\n",
            "Epoch 34/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.9657 - val_accuracy: 0.6040 - val_loss: 0.9673\n",
            "Epoch 35/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 0.9651 - val_accuracy: 0.6076 - val_loss: 0.9548\n",
            "Epoch 36/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6048 - loss: 0.9639 - val_accuracy: 0.6008 - val_loss: 0.9725\n",
            "Epoch 37/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 0.9676 - val_accuracy: 0.6088 - val_loss: 0.9550\n",
            "Epoch 38/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6014 - loss: 0.9708 - val_accuracy: 0.6134 - val_loss: 0.9381\n",
            "Epoch 39/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6058 - loss: 0.9610 - val_accuracy: 0.6172 - val_loss: 0.9481\n",
            "Epoch 40/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6053 - loss: 0.9604 - val_accuracy: 0.6063 - val_loss: 0.9561\n",
            "Epoch 41/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.6109 - loss: 0.9512 - val_accuracy: 0.6149 - val_loss: 0.9385\n",
            "Epoch 42/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6068 - loss: 0.9486 - val_accuracy: 0.6134 - val_loss: 0.9366\n",
            "Epoch 43/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6068 - loss: 0.9563 - val_accuracy: 0.6113 - val_loss: 0.9441\n",
            "Epoch 44/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6098 - loss: 0.9492 - val_accuracy: 0.6091 - val_loss: 0.9500\n",
            "Epoch 45/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6148 - loss: 0.9468 - val_accuracy: 0.6172 - val_loss: 0.9309\n",
            "Epoch 46/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.9388 - val_accuracy: 0.6095 - val_loss: 0.9377\n",
            "Epoch 47/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6161 - loss: 0.9385 - val_accuracy: 0.6170 - val_loss: 0.9366\n",
            "Epoch 48/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6132 - loss: 0.9429 - val_accuracy: 0.6124 - val_loss: 0.9406\n",
            "Epoch 49/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6132 - loss: 0.9427 - val_accuracy: 0.6077 - val_loss: 0.9422\n",
            "Epoch 50/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6172 - loss: 0.9353 - val_accuracy: 0.6176 - val_loss: 0.9379\n",
            "Epoch 51/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6200 - loss: 0.9325 - val_accuracy: 0.6133 - val_loss: 0.9342\n",
            "Epoch 52/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6184 - loss: 0.9303 - val_accuracy: 0.6203 - val_loss: 0.9311\n",
            "Epoch 53/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.9363 - val_accuracy: 0.6200 - val_loss: 0.9299\n",
            "Epoch 54/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6133 - loss: 0.9452 - val_accuracy: 0.6148 - val_loss: 0.9293\n",
            "Epoch 55/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6206 - loss: 0.9253 - val_accuracy: 0.6185 - val_loss: 0.9227\n",
            "Epoch 56/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6138 - loss: 0.9351 - val_accuracy: 0.6211 - val_loss: 0.9235\n",
            "Epoch 57/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6187 - loss: 0.9273 - val_accuracy: 0.6250 - val_loss: 0.9193\n",
            "Epoch 58/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6162 - loss: 0.9332 - val_accuracy: 0.6217 - val_loss: 0.9119\n",
            "Epoch 59/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6175 - loss: 0.9287 - val_accuracy: 0.6192 - val_loss: 0.9223\n",
            "Epoch 60/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6175 - loss: 0.9249 - val_accuracy: 0.6216 - val_loss: 0.9285\n",
            "Epoch 61/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6213 - loss: 0.9187 - val_accuracy: 0.6229 - val_loss: 0.9125\n",
            "Epoch 62/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6221 - loss: 0.9229 - val_accuracy: 0.6243 - val_loss: 0.9075\n",
            "Epoch 63/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6179 - loss: 0.9255 - val_accuracy: 0.6280 - val_loss: 0.9213\n",
            "Epoch 64/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6240 - loss: 0.9173 - val_accuracy: 0.6173 - val_loss: 0.9148\n",
            "Epoch 65/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6249 - loss: 0.9134 - val_accuracy: 0.6229 - val_loss: 0.9153\n",
            "Epoch 66/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6219 - loss: 0.9180 - val_accuracy: 0.6257 - val_loss: 0.9083\n",
            "Epoch 67/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6223 - loss: 0.9146 - val_accuracy: 0.6232 - val_loss: 0.9066\n",
            "Epoch 68/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6245 - loss: 0.9123 - val_accuracy: 0.6252 - val_loss: 0.8972\n",
            "Epoch 69/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6261 - loss: 0.9094 - val_accuracy: 0.6259 - val_loss: 0.9104\n",
            "Epoch 70/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6255 - loss: 0.9098 - val_accuracy: 0.6272 - val_loss: 0.8950\n",
            "Epoch 71/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6205 - loss: 0.9152 - val_accuracy: 0.6203 - val_loss: 0.9109\n",
            "Epoch 72/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6267 - loss: 0.9072 - val_accuracy: 0.6276 - val_loss: 0.8993\n",
            "Epoch 73/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6214 - loss: 0.9115 - val_accuracy: 0.6280 - val_loss: 0.9001\n",
            "Epoch 74/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6268 - loss: 0.9012 - val_accuracy: 0.6268 - val_loss: 0.9126\n",
            "Epoch 75/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6197 - loss: 0.9148 - val_accuracy: 0.6297 - val_loss: 0.8969\n",
            "Epoch 76/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6248 - loss: 0.9051 - val_accuracy: 0.6393 - val_loss: 0.8868\n",
            "Epoch 77/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6289 - loss: 0.9017 - val_accuracy: 0.6166 - val_loss: 0.9057\n",
            "Epoch 78/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6277 - loss: 0.9043 - val_accuracy: 0.6363 - val_loss: 0.8819\n",
            "Epoch 79/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6307 - loss: 0.8947 - val_accuracy: 0.6283 - val_loss: 0.8968\n",
            "Epoch 80/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6303 - loss: 0.8975 - val_accuracy: 0.6258 - val_loss: 0.8959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MODELO ELEGIDO\n",
        "\n",
        "# Cambio de batch size\n",
        "train_dataset_64 = train_dataset.unbatch().batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset_64 = val_dataset.unbatch().batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"\\n===== MODELO D =====\")\n",
        "model_D = crear_modelo(256, 128, 64, lr=0.0005)\n",
        "history_D = model_D.fit(train_dataset_64,\n",
        "                        validation_data=val_dataset_64,\n",
        "                        epochs=80)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "othPtlmf8hlw",
        "outputId": "6d9a87b1-5dcb-448d-dcfa-d6d1e174dd02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== MODELO D =====\n",
            "Epoch 1/80\n",
            "    648/Unknown \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4998 - loss: 1.2560"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4998 - loss: 1.2558 - val_accuracy: 0.5370 - val_loss: 1.1271\n",
            "Epoch 2/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5474 - loss: 1.1040 - val_accuracy: 0.5601 - val_loss: 1.0840\n",
            "Epoch 3/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5549 - loss: 1.0905 - val_accuracy: 0.5643 - val_loss: 1.0793\n",
            "Epoch 4/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5593 - loss: 1.0910 - val_accuracy: 0.5588 - val_loss: 1.0748\n",
            "Epoch 5/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5685 - loss: 1.0645 - val_accuracy: 0.5584 - val_loss: 1.0681\n",
            "Epoch 6/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5710 - loss: 1.0641 - val_accuracy: 0.5717 - val_loss: 1.0592\n",
            "Epoch 7/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5726 - loss: 1.0582 - val_accuracy: 0.5727 - val_loss: 1.0560\n",
            "Epoch 8/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5779 - loss: 1.0525 - val_accuracy: 0.5790 - val_loss: 1.0355\n",
            "Epoch 9/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5784 - loss: 1.0415 - val_accuracy: 0.5810 - val_loss: 1.0341\n",
            "Epoch 10/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5809 - loss: 1.0310 - val_accuracy: 0.5781 - val_loss: 1.0355\n",
            "Epoch 11/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.5840 - loss: 1.0319 - val_accuracy: 0.5890 - val_loss: 1.0182\n",
            "Epoch 12/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5857 - loss: 1.0238 - val_accuracy: 0.5847 - val_loss: 1.0204\n",
            "Epoch 13/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5861 - loss: 1.0156 - val_accuracy: 0.5870 - val_loss: 1.0132\n",
            "Epoch 14/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5905 - loss: 1.0127 - val_accuracy: 0.5841 - val_loss: 1.0213\n",
            "Epoch 15/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5897 - loss: 1.0156 - val_accuracy: 0.5881 - val_loss: 1.0119\n",
            "Epoch 16/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5889 - loss: 1.0160 - val_accuracy: 0.5928 - val_loss: 1.0051\n",
            "Epoch 17/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5911 - loss: 1.0074 - val_accuracy: 0.5919 - val_loss: 1.0048\n",
            "Epoch 18/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5876 - loss: 1.0107 - val_accuracy: 0.5917 - val_loss: 1.0022\n",
            "Epoch 19/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5936 - loss: 0.9991 - val_accuracy: 0.5882 - val_loss: 0.9975\n",
            "Epoch 20/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5930 - loss: 0.9917 - val_accuracy: 0.5971 - val_loss: 0.9942\n",
            "Epoch 21/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5959 - loss: 0.9974 - val_accuracy: 0.6006 - val_loss: 0.9852\n",
            "Epoch 22/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5950 - loss: 0.9933 - val_accuracy: 0.5975 - val_loss: 0.9857\n",
            "Epoch 23/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5973 - loss: 0.9927 - val_accuracy: 0.5980 - val_loss: 0.9871\n",
            "Epoch 24/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5953 - loss: 0.9891 - val_accuracy: 0.5951 - val_loss: 0.9914\n",
            "Epoch 25/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5932 - loss: 0.9933 - val_accuracy: 0.5971 - val_loss: 0.9867\n",
            "Epoch 26/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6012 - loss: 0.9808 - val_accuracy: 0.6039 - val_loss: 0.9790\n",
            "Epoch 27/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5961 - loss: 0.9827 - val_accuracy: 0.6092 - val_loss: 0.9678\n",
            "Epoch 28/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6022 - loss: 0.9756 - val_accuracy: 0.6099 - val_loss: 0.9677\n",
            "Epoch 29/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6038 - loss: 0.9743 - val_accuracy: 0.5963 - val_loss: 0.9827\n",
            "Epoch 30/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5940 - loss: 0.9780 - val_accuracy: 0.6066 - val_loss: 0.9672\n",
            "Epoch 31/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6051 - loss: 0.9713 - val_accuracy: 0.6119 - val_loss: 0.9571\n",
            "Epoch 32/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6025 - loss: 0.9637 - val_accuracy: 0.6088 - val_loss: 0.9577\n",
            "Epoch 33/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6040 - loss: 0.9692 - val_accuracy: 0.6031 - val_loss: 0.9568\n",
            "Epoch 34/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6058 - loss: 0.9647 - val_accuracy: 0.6100 - val_loss: 0.9540\n",
            "Epoch 35/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6045 - loss: 0.9677 - val_accuracy: 0.6036 - val_loss: 0.9589\n",
            "Epoch 36/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6073 - loss: 0.9607 - val_accuracy: 0.6039 - val_loss: 0.9626\n",
            "Epoch 37/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6102 - loss: 0.9592 - val_accuracy: 0.6100 - val_loss: 0.9596\n",
            "Epoch 38/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6083 - loss: 0.9548 - val_accuracy: 0.6137 - val_loss: 0.9415\n",
            "Epoch 39/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6110 - loss: 0.9500 - val_accuracy: 0.6120 - val_loss: 0.9471\n",
            "Epoch 40/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6088 - loss: 0.9488 - val_accuracy: 0.6068 - val_loss: 0.9485\n",
            "Epoch 41/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6105 - loss: 0.9494 - val_accuracy: 0.6112 - val_loss: 0.9390\n",
            "Epoch 42/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6072 - loss: 0.9546 - val_accuracy: 0.6131 - val_loss: 0.9482\n",
            "Epoch 43/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6081 - loss: 0.9517 - val_accuracy: 0.6050 - val_loss: 0.9568\n",
            "Epoch 44/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6103 - loss: 0.9436 - val_accuracy: 0.6105 - val_loss: 0.9451\n",
            "Epoch 45/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6072 - loss: 0.9538 - val_accuracy: 0.6175 - val_loss: 0.9361\n",
            "Epoch 46/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6124 - loss: 0.9392 - val_accuracy: 0.6173 - val_loss: 0.9336\n",
            "Epoch 47/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6097 - loss: 0.9424 - val_accuracy: 0.6141 - val_loss: 0.9397\n",
            "Epoch 48/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6170 - loss: 0.9326 - val_accuracy: 0.6145 - val_loss: 0.9305\n",
            "Epoch 49/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6106 - loss: 0.9400 - val_accuracy: 0.6182 - val_loss: 0.9314\n",
            "Epoch 50/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6131 - loss: 0.9364 - val_accuracy: 0.6090 - val_loss: 0.9414\n",
            "Epoch 51/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6141 - loss: 0.9360 - val_accuracy: 0.6179 - val_loss: 0.9243\n",
            "Epoch 52/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6153 - loss: 0.9413 - val_accuracy: 0.6118 - val_loss: 0.9374\n",
            "Epoch 53/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6174 - loss: 0.9357 - val_accuracy: 0.6178 - val_loss: 0.9189\n",
            "Epoch 54/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6159 - loss: 0.9307 - val_accuracy: 0.6253 - val_loss: 0.9124\n",
            "Epoch 55/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6174 - loss: 0.9187 - val_accuracy: 0.6246 - val_loss: 0.9174\n",
            "Epoch 56/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6201 - loss: 0.9244 - val_accuracy: 0.6251 - val_loss: 0.9158\n",
            "Epoch 57/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6211 - loss: 0.9202 - val_accuracy: 0.6231 - val_loss: 0.9225\n",
            "Epoch 58/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6205 - loss: 0.9210 - val_accuracy: 0.6211 - val_loss: 0.9184\n",
            "Epoch 59/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6158 - loss: 0.9241 - val_accuracy: 0.6240 - val_loss: 0.9210\n",
            "Epoch 60/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6188 - loss: 0.9213 - val_accuracy: 0.6199 - val_loss: 0.9232\n",
            "Epoch 61/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6202 - loss: 0.9213 - val_accuracy: 0.6296 - val_loss: 0.9022\n",
            "Epoch 62/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6193 - loss: 0.9153 - val_accuracy: 0.6311 - val_loss: 0.9000\n",
            "Epoch 63/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6194 - loss: 0.9180 - val_accuracy: 0.6262 - val_loss: 0.9007\n",
            "Epoch 64/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6210 - loss: 0.9167 - val_accuracy: 0.6295 - val_loss: 0.9022\n",
            "Epoch 65/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6247 - loss: 0.9078 - val_accuracy: 0.6272 - val_loss: 0.9060\n",
            "Epoch 66/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6240 - loss: 0.9078 - val_accuracy: 0.6264 - val_loss: 0.9104\n",
            "Epoch 67/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6244 - loss: 0.9132 - val_accuracy: 0.6269 - val_loss: 0.9118\n",
            "Epoch 68/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6254 - loss: 0.9139 - val_accuracy: 0.6321 - val_loss: 0.8980\n",
            "Epoch 69/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6267 - loss: 0.9012 - val_accuracy: 0.6173 - val_loss: 0.9170\n",
            "Epoch 70/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6268 - loss: 0.9017 - val_accuracy: 0.6221 - val_loss: 0.9172\n",
            "Epoch 71/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6246 - loss: 0.9132 - val_accuracy: 0.6283 - val_loss: 0.8913\n",
            "Epoch 72/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6216 - loss: 0.9154 - val_accuracy: 0.6278 - val_loss: 0.8933\n",
            "Epoch 73/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6315 - loss: 0.8972 - val_accuracy: 0.6333 - val_loss: 0.8912\n",
            "Epoch 74/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6340 - loss: 0.8978 - val_accuracy: 0.6280 - val_loss: 0.9002\n",
            "Epoch 75/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6329 - loss: 0.8961 - val_accuracy: 0.6383 - val_loss: 0.8856\n",
            "Epoch 76/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6257 - loss: 0.9043 - val_accuracy: 0.6288 - val_loss: 0.9033\n",
            "Epoch 77/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6262 - loss: 0.8985 - val_accuracy: 0.6225 - val_loss: 0.9074\n",
            "Epoch 78/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6308 - loss: 0.9045 - val_accuracy: 0.6290 - val_loss: 0.8938\n",
            "Epoch 79/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6302 - loss: 0.8937 - val_accuracy: 0.6274 - val_loss: 0.9001\n",
            "Epoch 80/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6332 - loss: 0.8958 - val_accuracy: 0.6315 - val_loss: 0.8835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mejor val_accuracy Modelo D:\", max(history_D.history['val_accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TPMH0nIOjDQ",
        "outputId": "33c99552-0c3a-4dae-a908-733ce057f118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor val_accuracy Modelo D: 0.638294517993927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo D\n",
        "test_loss, test_acc = model_D.evaluate(test_dataset)\n",
        "\n",
        "print(\"===== RESULTADOS EN TEST =====\")\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzgc080COnso",
        "outputId": "9e2d36aa-2247-4e3a-ecd5-8c80de64b2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6327 - loss: 0.9033\n",
            "===== RESULTADOS EN TEST =====\n",
            "Test Loss: 0.8969751596450806\n",
            "Test Accuracy: 0.631177544593811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones\n",
        "import numpy as np\n",
        "\n",
        "y_pred_prob = model_D.predict(test_dataset)\n",
        "\n",
        "# Si es multiclase\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "if len(y_true.shape) > 1:\n",
        "    y_true = np.argmax(y_true, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4k4e_zWPzFv",
        "outputId": "fc199d5a-860b-4720-e644-243661603ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusion\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Matriz de Confusión - TEST\")\n",
        "plt.xlabel(\"Predicho\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "nY9TKX_bP_BP",
        "outputId": "bf549171-59ce-4ea0-9540-f999cf2217fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.51      0.45      3911\n",
            "           1       0.15      0.10      0.12      1455\n",
            "           2       0.31      0.34      0.33      2990\n",
            "           3       0.12      0.05      0.07      1142\n",
            "           4       0.00      0.00      0.00         9\n",
            "           5       0.33      0.02      0.03        57\n",
            "           6       0.00      0.00      0.00         3\n",
            "           8       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.33      9571\n",
            "   macro avg       0.17      0.13      0.13      9571\n",
            "weighted avg       0.30      0.33      0.31      9571\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mejor val_accuracy Modelo A:\", max(history_A.history['val_accuracy']))\n",
        "print(\"Mejor val_accuracy Modelo B:\", max(history_B.history['val_accuracy']))\n",
        "print(\"Mejor val_accuracy Modelo C:\", max(history_C.history['val_accuracy']))\n",
        "print(\"Mejor val_accuracy Modelo D:\", max(history_D.history['val_accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6JcxgXl4WmZ",
        "outputId": "8f3837e3-b359-4a75-8bef-2cd870125797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor val_accuracy Modelo A: 0.6021631956100464\n",
            "Mejor val_accuracy Modelo B: 0.6194843053817749\n",
            "Mejor val_accuracy Modelo C: 0.6339054703712463\n",
            "Mejor val_accuracy Modelo D: 0.6393133997917175\n"
          ]
        }
      ]
    }
  ]
}