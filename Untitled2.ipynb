{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiguelGonzalez197/Proyectos-Deep-Learning/blob/Oscar-Herrera/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d97ZnsBPCYTN",
        "outputId": "ad038af2-0e1a-43f5-a524-e91c410f0867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Proyectos-Deep-Learning'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 14 (delta 4), reused 3 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (14/14), 18.32 KiB | 670.00 KiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b Sebastian-Gutierrez https://github.com/MiguelGonzalez197/Proyectos-Deep-Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Ttq8WwCPMGKl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Carga de dataset .xslx\n",
        "\n",
        "uploaded=files.upload()\n",
        "nombre_archivo=list(uploaded.keys())[0]\n",
        "df=pd.read_csv(nombre_archivo,sep=\";\",encoding=\"latin1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "mAx2ZMeQCc3J",
        "outputId": "a2fccfae-d296-424a-c817-e6e4d2de8286"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-35268cf3-cbcf-4ea6-897e-49f1d1bd9d5d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-35268cf3-cbcf-4ea6-897e-49f1d1bd9d5d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Dataset_ExamenesLaboratorio_ConsultaExterna_PatologíasRelacionadas_Obesidad_202405_202411.csv to Dataset_ExamenesLaboratorio_ConsultaExterna_PatologíasRelacionadas_Obesidad_202405_202411 (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PreProcesamiento del dataset\n",
        "f=df.fillna(0)\n",
        "\n",
        "cod_dep,map_Dep=pd.factorize(df[\"DEPARTAMENTO\"])\n",
        "df[\"DEPARTAMENTO\"]=cod_dep +1\n",
        "\n",
        "cod_Prov,map_Prov=pd.factorize(df[\"PROVINCIA\"])\n",
        "df[\"PROVINCIA\"]=cod_Prov+1\n",
        "\n",
        "cod_Dist,map_Dist=pd.factorize(df[\"DISTRITO\"])\n",
        "df[\"DISTRITO\"]=cod_Dist+1\n",
        "\n",
        "df['EDAD_PACIENTE'] = pd.cut(\n",
        "    df['EDAD_PACIENTE'],\n",
        "    bins=[0, 10, 20, 30,40,50,60,70,80,90,100,110],\n",
        "    labels=[1, 2, 3,4,5,6,7,8,9,10,11],\n",
        "    right=False\n",
        ")\n",
        "\n",
        "cod_sex,map_Sex=pd.factorize(df[\"SEXO_PACIENTE\"])\n",
        "df[\"SEXO_PACIENTE\"]=cod_sex+1\n",
        "\n",
        "cod_Diag,map_Diag=pd.factorize(df[\"DIAGNOSTICO\"])\n",
        "df[\"DIAGNOSTICO\"]=cod_Diag+1\n",
        "\n",
        "cod_Serv,map_Serv=pd.factorize(df[\"SERVICIO_HOSPITALARIO\"])\n",
        "df[\"SERVICIO_HOSPITALARIO\"]=cod_Serv+1\n",
        "\n",
        "cod_Pro1,map_Pro1=pd.factorize(df[\"PROCEDIMIENTO_1\"])\n",
        "df[\"PROCEDIMIENTO_1\"]=cod_Pro1+1\n",
        "\n",
        "df.loc[\n",
        "    (df[\"UNIDADES_1\"] == \"mmol/lt\") & (df[\"PROCEDIMIENTO_1\"] == 1),\n",
        "    \"RESULTADO_1\"\n",
        "] *= 18\n",
        "\n",
        "df.loc[\n",
        "    (df[\"UNIDADES_1\"] == \"mmol/lt\") & (df[\"PROCEDIMIENTO_1\"] == 2),\n",
        "    \"RESULTADO_1\"\n",
        "] *= 88.57\n",
        "\n",
        "cod_Pro1,map_Pro1=pd.factorize(df[\"PROCEDIMIENTO_2\"])\n",
        "df[\"PROCEDIMIENTO_2\"]=cod_Pro1+1\n",
        "\n",
        "df.loc[\n",
        "    (df[\"UNIDADES_2\"] == \"mmol/lt\") & (df[\"PROCEDIMIENTO_2\"] == 1),\n",
        "    \"RESULTADO_2\"\n",
        "] *= 18\n",
        "\n",
        "df.loc[\n",
        "    (df[\"UNIDADES_2\"] == \"mmol/lt\") & (df[\"PROCEDIMIENTO_2\"] == 2),\n",
        "    \"RESULTADO_2\"\n",
        "] *= 88.57\n",
        "\n",
        "\n",
        "df = df.drop(df.columns[[0, 4, 5,6,7,10,11,12,14,16,17,18,19,22,23,26,27]], axis=1)\n",
        "\n",
        "\n",
        "df.to_excel(\"resultado.xlsx\",index=False)#Exportacion de dataset preprocesado en .xlsx\n"
      ],
      "metadata": {
        "id": "geyN3L-tCdgZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mapas de categorizacion numerica a cada columna de informacion\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Dep)}\n",
        "print(mapeo)\n",
        "\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Prov)}\n",
        "print(mapeo)\n",
        "\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Dist)}\n",
        "print(mapeo)\n",
        "\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Sex)}\n",
        "print(mapeo)\n",
        "\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Diag)}\n",
        "print(mapeo)\n",
        "\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Serv)}\n",
        "print(mapeo)\n",
        "\n",
        "mapeo = {valor: i + 1 for i, valor in enumerate(map_Pro1)}\n",
        "print(mapeo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIU2qrD_Cgeh",
        "outputId": "3d53dea3-5ab2-47b0-f55a-f6d4125d0a86"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'LIMA': 1, 'LA LIBERTAD': 2, 'CAJAMARCA': 3, 'CALLAO': 4, 'AREQUIPA': 5, 'ANCASH': 6, 'HUANUCO': 7, 'SAN MARTIN': 8, 'TUMBES': 9, 'JUNIN': 10, 'LORETO': 11, 'AMAZONAS': 12, 'PIURA': 13, 'ICA': 14, 'TACNA': 15, 'AYACUCHO': 16, 'APURIMAC': 17, 'LAMBAYEQUE': 18, 'MOQUEGUA': 19, 'PUNO': 20, 'CUSCO': 21, 'PASCO': 22, 'MADRE DE DIOS': 23, 'HUANCAVELICA': 24}\n",
            "{'LIMA': 1, 'TRUJILLO': 2, 'JAEN': 3, 'CALLAO': 4, 'AREQUIPA': 5, 'SANTA': 6, 'HUANUCO': 7, 'SAN MARTIN': 8, 'TUMBES': 9, 'HUANCAYO': 10, 'MAYNAS': 11, 'CHACHAPOYAS': 12, 'HUAURA': 13, 'PIURA': 14, 'CAJAMARCA': 15, 'ICA': 16, 'TACNA': 17, 'HUARAL': 18, 'HUAMANGA': 19, 'ABANCAY': 20, 'CHICLAYO': 21, 'LAMBAYEQUE': 22, 'MOYOBAMBA': 23, 'HUARAZ': 24, 'ANDAHUAYLAS': 25, 'MARISCAL NIETO': 26, 'SAN ROMAN': 27, 'CUSCO': 28, 'CHANCHAMAYO': 29, 'CASMA': 30, 'CANETE': 31, 'MARISCAL CACERES': 32, 'FERRENAFE': 33, 'ILO': 34, 'PUNO': 35, 'LORETO': 36, 'PASCO': 37, 'OXAPAMPA': 38, 'TALARA': 39, 'ISLAY': 40, 'CHEPEN': 41, 'CONCEPCION': 42, 'CHINCHA': 43, 'PACASMAYO': 44, 'SULLANA': 45, 'ALTO AMAZONAS': 46, 'SAN IGNACIO': 47, 'POMABAMBA': 48, 'UTCUBAMBA': 49, 'PISCO': 50, 'VIRU': 51, 'ASCOPE': 52, 'CASTILLA': 53, 'HUAYLAS': 54, 'CAMANA': 55, 'TAMBOPATA': 56, 'HUANCAVELICA': 57, 'CUTERVO': 58, 'YAULI': 59, 'RIOJA': 60, 'BAGUA': 61, 'CHUPACA': 62, 'CHOTA': 63, 'CANCHIS': 64, 'BARRANCA': 65, 'TARMA': 66, 'AYMARAES': 67, 'LA CONVENCION': 68, 'JAUJA': 69, 'SECHURA': 70, 'JORGE BASADRE': 71, 'MORROPON': 72, 'BELLAVISTA': 73, 'YUNGAY': 74, 'ACOMAYO': 75, 'GRAN CHIMU': 76, 'HUARMEY': 77, 'SATIPO': 78, 'LA UNION': 79, 'HUALGAYOC': 80, 'LAMPA': 81, 'CHINCHEROS': 82, 'LAMAS': 83, 'SANCHEZ CARRION': 84, 'CALCA': 85, 'URUBAMBA': 86, 'BONGARA': 87, 'LUYA': 88, 'TARATA': 89, 'MANU': 90, 'CARHUAZ': 91, 'HUALLAGA': 92, 'PAUCARTAMBO': 93, 'HUARI': 94, 'CAYLLOMA': 95, 'CHUCUITO': 96, 'ESPINAR': 97, 'CONDESUYOS': 98}\n",
            "{'MIRAFLORES': 1, 'VICTOR LARCO HERRERA': 2, 'JAEN': 3, 'SAN JUAN DE LURIGANCHO': 4, 'VENTANILLA': 5, 'SAN LUIS': 6, 'YANAHUARA': 7, 'TRUJILLO': 8, 'CHIMBOTE': 9, 'SANTIAGO DE SURCO': 10, 'LA MOLINA': 11, 'SURQUILLO': 12, 'LAREDO': 13, 'AMARILIS': 14, 'TARAPOTO': 15, 'TUMBES': 16, 'LA ESPERANZA': 17, 'COMAS': 18, 'EL TAMBO': 19, 'LOS OLIVOS': 20, 'VILLA EL SALVADOR': 21, 'SAN JUAN BAUTISTA': 22, 'CHACHAPOYAS': 23, 'SAYAN': 24, 'LIMA': 25, 'PIURA': 26, 'SAN ISIDRO': 27, 'AREQUIPA': 28, 'CAJAMARCA': 29, 'ICA': 30, 'CALLAO': 31, 'INDEPENDENCIA': 32, 'PUENTE PIEDRA': 33, 'CHORRILLOS': 34, 'HUANCAYO': 35, 'TACNA': 36, 'CHANCAY': 37, 'SANTIAGO': 38, 'HUANUCO': 39, 'RIMAC': 40, 'CARABAYLLO': 41, 'AYACUCHO': 42, 'HUARAL': 43, 'LA VICTORIA': 44, 'ABANCAY': 45, 'SAN MIGUEL': 46, 'CALANA': 47, 'CHICLAYO': 48, 'LAMBAYEQUE': 49, 'MOYOBAMBA': 50, 'PAUCARPATA': 51, 'HUARAZ': 52, 'ANDAHUAYLAS': 53, 'SOCABAYA': 54, 'ALTO SELVA ALEGRE': 55, 'BELLAVISTA': 56, 'LINCE': 57, 'MOQUEGUA': 58, 'SAN JUAN DE MIRAFLORES': 59, 'IQUITOS': 60, 'JULIACA': 61, 'CUSCO': 62, 'CHANCHAMAYO': 63, 'CASMA': 64, 'SAN VICENTE DE CANETE': 65, 'JUANJUI': 66, 'LURIGANCHO': 67, 'FERRENAFE': 68, 'ILO': 69, 'PUNO': 70, 'JOSE LEONARDO ORTIZ': 71, 'MORALES': 72, 'EL AGUSTINO': 73, 'SANTA ANITA': 74, 'HUACHO': 75, 'MOCHE': 76, 'FLORENCIA DE MORA': 77, 'JESUS MARIA': 78, 'NAUTA': 79, 'CHAUPIMARCA': 80, 'OXAPAMPA': 81, 'PARINAS': 82, 'SAN SEBASTIAN': 83, 'MOLLENDO': 84, 'CHEPEN': 85, 'CONCEPCION': 86, 'CHINCHA ALTA': 87, 'LURIN': 88, 'SAMEGUA': 89, 'PATAPO': 90, 'PACASMAYO': 91, 'SULLANA': 92, 'YURIMAGUAS': 93, 'SAN IGNACIO': 94, 'POMABAMBA': 95, 'BAGUA GRANDE': 96, 'PISCO': 97, 'VIRU': 98, 'CHOCOPE': 99, 'APLAO': 100, 'CARAZ': 101, 'EL PORVENIR': 102, 'CASTILLA': 103, 'SAMUEL PASTOR': 104, 'JAYANCA': 105, 'CHILCA': 106, 'ETEN': 107, 'TAMBOPATA': 108, 'PIMENTEL': 109, 'ASCENSION': 110, 'ASCOPE': 111, 'CUTERVO': 112, 'SAN PEDRO DE LLOC': 113, 'LA OROYA': 114, 'RIOJA': 115, 'PUNCHANA': 116, 'SAN JOSE': 117, 'LA PECA': 118, 'LA BREA': 119, 'CHUPACA': 120, 'CHOTA': 121, 'OYOTUN': 122, 'JACOBO HUNTER': 123, 'CATACAOS': 124, 'SICUANI': 125, 'MOTUPE': 126, 'NEPENA': 127, 'CASA GRANDE': 128, 'CHAO': 129, 'MALA': 130, 'PARAMONGA': 131, 'TARMA': 132, 'CHALHUANCA': 133, 'COISHCO': 134, 'SANTA ANA': 135, 'LA JOYA': 136, 'TUCUME': 137, 'JAUJA': 138, 'SECHURA': 139, 'YURA': 140, 'LOCUMBA': 141, 'CHULUCANAS': 142, 'YUNGAY': 143, 'ACOMAYO': 144, 'TUPAC AMARU INCA': 145, 'IGNACIO ESCUDERO': 146, 'SANTIAGO DE CAO': 147, 'CASCAS': 148, 'HUARMEY': 149, 'SATIPO': 150, 'TAMBO GRANDE': 151, 'COTAHUASI': 152, 'LA UNION': 153, 'SAN CLEMENTE': 154, 'HUALGAYOC': 155, 'LAMPA': 156, 'ISLAY': 157, 'OLMOS': 158, 'YANACANCHA': 159, 'PUCARA': 160, 'HUANCHACO': 161, 'VITOR': 162, 'JEQUETEPEQUE': 163, 'NUEVA CAJAMARCA': 164, 'RAZURI': 165, 'URACA': 166, 'CHINCHEROS': 167, 'SALAVERRY': 168, 'LAMAS': 169, 'HUAMACHUCO': 170, 'TAMBO DE MORA': 171, 'CALCA': 172, 'URUBAMBA': 173, 'LAGUNAS': 174, 'PAIJAN': 175, 'HUARIACA': 176, 'JAZAN': 177, 'VILLA RICA': 178, 'LAMUD': 179, 'OCALLI': 180, 'TARATA': 181, 'PICHANAQUI': 182, 'MANU': 183, 'CARHUAZ': 184, 'EL ALTO': 185, 'SAPOSOA': 186, 'ITE': 187, 'GUADALUPE': 188, 'PAUCARTAMBO': 189, 'LA TINGUINA': 190, 'HUARI': 191, 'CHIVAY': 192, 'DESAGUADERO': 193, 'ESPINAR': 194, 'CURAHUASI': 195, 'CHUQUIBAMBA': 196, 'ILABAYA': 197}\n",
            "{'FEMENINO': 1, 'MASCULINO': 2}\n",
            "{'HIPOTIROIDISMO, NO ESPECIFICADO': 1, 'SOBREPESO': 2, 'OBESIDAD, NO ESPECIFICADA': 3, 'OBESIDAD DEBIDA A EXCESO DE CALORIAS': 4, 'CONSULTA PARA INSTRUCCION Y VIGILANCIA DE LA DIETA': 5, 'OTROS TIPOS DE OBESIDAD': 6, 'OBESIDAD EXTREMA CON HIPOVENTILACION ALVEOLAR': 7, 'OTROS TRASTORNOS DE LA GLANDULA HIPOFISIS': 8, 'OBESIDAD INDUCIDA POR DROGAS': 9}\n",
            "{'ENDOCRINOLOGIA': 1, 'PEDIATRIA': 2, 'MEDICINA INTERNA': 3, 'CIRUGIA GENERAL': 4, 'MEDICINA GENERAL': 5, 'MEDICINA FAMILIAR Y COMUNITARIA': 6, 'CARDIOLOGIA': 7, 'GERIATRIA': 8, 'MEDICO DE PERSONAL': 9, 'NEUROLOGIA PEDIATRICA': 10, 'MEDICINA OCUPACIONAL Y DEL MEDIO AMBIENTE': 11, 'ESPECIALIDADES PEDIATRICAS': 12, 'ENDOCRINOLOGIA PEDIATRICA': 13, 'MEDICINA COMPLEMENTARIA': 14, 'GASTROENTEROLOGIA': 15, 'NEFROLOGIA': 16, 'ENFERMEDADES INFECCIOSAS Y TROPICALES': 17, 'NEUMOLOGIA': 18, 'OFTALMOLOGIA': 19, 'GINECOLOGIA Y OBSTETRICIA': 20, 'DERMATOLOGIA': 21, 'GINECOLOGIA': 22, 'NEUROLOGIA': 23, 'REUMATOLOGIA': 24, 'HEMATOLOGIA CLINICA': 25, 'OBSTETRICIA DE ALTO RIESGO': 26, 'PSIQUIATRIA': 27, 'UROLOGIA GENERAL': 28, 'ONCOLOGIA MEDICA': 29, 'CIRUGIA PEDIATRICA': 30, 'OBSTETRICIA': 31, 'ANESTESIA, ANALGESIA Y REANIMACION': 32, 'CIRUGIA DE TORAX Y CARDIOVASCULAR': 33, 'NEUROCIRUGIA': 34, 'HOSPITAL DE DIA': 35, 'MEDICINA NUCLEAR': 36, 'ORTOPEDIA Y TRAUMATOLOGIA': 37, 'CITOPATOLOGIA Y CITOGENETICA': 38, 'PSIQUIATRIA-INFANTO-JUVENIL': 39, 'TRASPLANTE DE HIGADO': 40, 'MEDICINA FISICA Y REHABILITACION': 41, 'CARDIOLOGIA INVASIVA': 42, 'MEDICINA DEL ADOLESCENTE': 43}\n",
            "{'TRIGLICERIDOS': 1, 'DOSAJE DE GLUCOSA EN SANGRE, CUANTITATIVO (EXCEPTO CINTA REACTIVA)': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exportacion de archivo .xlsx a un arreglo numpy\n",
        "df = pd.read_excel(\"resultado.xlsx\")\n",
        "\n",
        "y = df[\"DIAGNOSTICO\"]\n",
        "X = df.drop(columns=[\"DIAGNOSTICO\"])\n",
        "\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "#Cambio Oscar\n",
        "y = y.astype('int32') - 1\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Y0JdilNDHccb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aleatorizacion y distribucion del data set\n",
        "\n",
        "#Pesos para dataset train/val/test\n",
        "train_peso = 0.65\n",
        "val_peso   = 0.20\n",
        "test_peso  = 0.15\n",
        "\n",
        "total_size = len(X)\n",
        "train_size = int(train_peso * total_size)\n",
        "val_size   = int(val_peso * total_size)\n",
        "test_size  = total_size - train_size - val_size\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "dataset = dataset.shuffle(len(X), seed=42)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "rest_dataset  = dataset.skip(train_size)\n",
        "\n",
        "val_dataset   = rest_dataset.take(val_size)\n",
        "test_dataset  = rest_dataset.skip(val_size)\n",
        "\n",
        "#Division de dataset por lotes\n",
        "\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE) #Lotes del dataset para train\n",
        "val_dataset   = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE) #Lotes del dataset para val\n",
        "test_dataset  = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE) #Lotes del dataset para test\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Up9BtVSmMTwF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "input_dim = X.shape[1]\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "print(\"Número de características:\", input_dim)\n",
        "print(\"Número de clases:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4_mRKy68E_C",
        "outputId": "5f761b07-9546-43bc-c43c-b61252003dc0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de características: 10\n",
            "Número de clases: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Diagnósticos originales:\")\n",
        "for i, diag in enumerate(map_Diag):\n",
        "    print(f\"{i} → {diag}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fbm00O4HDFe",
        "outputId": "caed5ac1-841a-4d35-dc76-a2dbcc667336"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagnósticos originales:\n",
            "0 → HIPOTIROIDISMO, NO ESPECIFICADO\n",
            "1 → SOBREPESO\n",
            "2 → OBESIDAD, NO ESPECIFICADA\n",
            "3 → OBESIDAD DEBIDA A EXCESO DE CALORIAS\n",
            "4 → CONSULTA PARA INSTRUCCION Y VIGILANCIA DE LA DIETA\n",
            "5 → OTROS TIPOS DE OBESIDAD\n",
            "6 → OBESIDAD EXTREMA CON HIPOVENTILACION ALVEOLAR\n",
            "7 → OTROS TRASTORNOS DE LA GLANDULA HIPOFISIS\n",
            "8 → OBESIDAD INDUCIDA POR DROGAS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "\n",
        "input_dim = 10\n",
        "num_classes = 9\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', kernel_initializer=HeNormal(), input_shape=(input_dim,)),\n",
        "    Dense(64, activation='relu', kernel_initializer=HeNormal()),\n",
        "    Dense(32, activation='relu', kernel_initializer=HeNormal()),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Z2XArINzFHCp",
        "outputId": "13ab1b26-b6ce-43f5-a7e3-1cee9f2b0018"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m297\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">297</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,041\u001b[0m (47.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,041</span> (47.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,041\u001b[0m (47.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,041</span> (47.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=60\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_0IDKq3GZj9",
        "outputId": "ddcbd669-516e-48c4-80d9-1a041ef9d433"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5157 - loss: 1.2060 - val_accuracy: 0.5494 - val_loss: 1.0998\n",
            "Epoch 2/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5466 - loss: 1.1124 - val_accuracy: 0.5475 - val_loss: 1.0993\n",
            "Epoch 3/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5488 - loss: 1.0970 - val_accuracy: 0.5541 - val_loss: 1.0858\n",
            "Epoch 4/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5591 - loss: 1.0786 - val_accuracy: 0.5642 - val_loss: 1.0695\n",
            "Epoch 5/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5652 - loss: 1.0704 - val_accuracy: 0.5606 - val_loss: 1.0685\n",
            "Epoch 6/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5691 - loss: 1.0568 - val_accuracy: 0.5749 - val_loss: 1.0455\n",
            "Epoch 7/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5701 - loss: 1.0551 - val_accuracy: 0.5733 - val_loss: 1.0516\n",
            "Epoch 8/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5688 - loss: 1.0576 - val_accuracy: 0.5799 - val_loss: 1.0376\n",
            "Epoch 9/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5783 - loss: 1.0402 - val_accuracy: 0.5848 - val_loss: 1.0295\n",
            "Epoch 10/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5816 - loss: 1.0392 - val_accuracy: 0.5755 - val_loss: 1.0379\n",
            "Epoch 11/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5770 - loss: 1.0311 - val_accuracy: 0.5847 - val_loss: 1.0187\n",
            "Epoch 12/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5850 - loss: 1.0273 - val_accuracy: 0.5808 - val_loss: 1.0238\n",
            "Epoch 13/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5855 - loss: 1.0260 - val_accuracy: 0.5906 - val_loss: 1.0071\n",
            "Epoch 14/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5885 - loss: 1.0225 - val_accuracy: 0.5756 - val_loss: 1.0272\n",
            "Epoch 15/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5836 - loss: 1.0212 - val_accuracy: 0.5921 - val_loss: 1.0066\n",
            "Epoch 16/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5847 - loss: 1.0252 - val_accuracy: 0.5839 - val_loss: 1.0156\n",
            "Epoch 17/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5770 - loss: 1.0245 - val_accuracy: 0.5901 - val_loss: 1.0109\n",
            "Epoch 18/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5821 - loss: 1.0161 - val_accuracy: 0.5890 - val_loss: 1.0071\n",
            "Epoch 19/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 1.0059 - val_accuracy: 0.5994 - val_loss: 0.9962\n",
            "Epoch 20/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5880 - loss: 1.0033 - val_accuracy: 0.5848 - val_loss: 0.9989\n",
            "Epoch 21/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 1.0026 - val_accuracy: 0.5979 - val_loss: 0.9857\n",
            "Epoch 22/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5924 - loss: 1.0052 - val_accuracy: 0.5975 - val_loss: 0.9950\n",
            "Epoch 23/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5881 - loss: 1.0075 - val_accuracy: 0.5924 - val_loss: 1.0002\n",
            "Epoch 24/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5978 - loss: 0.9946 - val_accuracy: 0.6010 - val_loss: 0.9831\n",
            "Epoch 25/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5935 - loss: 0.9917 - val_accuracy: 0.5997 - val_loss: 0.9839\n",
            "Epoch 26/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5943 - loss: 0.9979 - val_accuracy: 0.6001 - val_loss: 0.9808\n",
            "Epoch 27/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5939 - loss: 0.9926 - val_accuracy: 0.6011 - val_loss: 0.9687\n",
            "Epoch 28/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5988 - loss: 0.9784 - val_accuracy: 0.5971 - val_loss: 0.9815\n",
            "Epoch 29/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5977 - loss: 0.9827 - val_accuracy: 0.6040 - val_loss: 0.9768\n",
            "Epoch 30/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5977 - loss: 0.9836 - val_accuracy: 0.6016 - val_loss: 0.9697\n",
            "Epoch 31/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5998 - loss: 0.9779 - val_accuracy: 0.5962 - val_loss: 0.9843\n",
            "Epoch 32/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5987 - loss: 0.9815 - val_accuracy: 0.6022 - val_loss: 0.9656\n",
            "Epoch 33/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6009 - loss: 0.9716 - val_accuracy: 0.6069 - val_loss: 0.9643\n",
            "Epoch 34/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 0.9784 - val_accuracy: 0.6008 - val_loss: 0.9710\n",
            "Epoch 35/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6072 - loss: 0.9615 - val_accuracy: 0.5995 - val_loss: 0.9656\n",
            "Epoch 36/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 0.9683 - val_accuracy: 0.6035 - val_loss: 0.9620\n",
            "Epoch 37/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6035 - loss: 0.9711 - val_accuracy: 0.6045 - val_loss: 0.9598\n",
            "Epoch 38/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6031 - loss: 0.9658 - val_accuracy: 0.6116 - val_loss: 0.9544\n",
            "Epoch 39/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6073 - loss: 0.9603 - val_accuracy: 0.5942 - val_loss: 0.9684\n",
            "Epoch 40/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6029 - loss: 0.9643 - val_accuracy: 0.6025 - val_loss: 0.9651\n",
            "Epoch 41/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6075 - loss: 0.9607 - val_accuracy: 0.6033 - val_loss: 0.9680\n",
            "Epoch 42/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6065 - loss: 0.9569 - val_accuracy: 0.6091 - val_loss: 0.9585\n",
            "Epoch 43/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6093 - loss: 0.9597 - val_accuracy: 0.6035 - val_loss: 0.9609\n",
            "Epoch 44/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6043 - loss: 0.9566 - val_accuracy: 0.6084 - val_loss: 0.9498\n",
            "Epoch 45/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6103 - loss: 0.9519 - val_accuracy: 0.6163 - val_loss: 0.9352\n",
            "Epoch 46/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6064 - loss: 0.9623 - val_accuracy: 0.6078 - val_loss: 0.9468\n",
            "Epoch 47/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6086 - loss: 0.9536 - val_accuracy: 0.6160 - val_loss: 0.9403\n",
            "Epoch 48/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.9557 - val_accuracy: 0.6096 - val_loss: 0.9490\n",
            "Epoch 49/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6047 - loss: 0.9526 - val_accuracy: 0.6070 - val_loss: 0.9531\n",
            "Epoch 50/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6084 - loss: 0.9523 - val_accuracy: 0.6142 - val_loss: 0.9359\n",
            "Epoch 51/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6112 - loss: 0.9490 - val_accuracy: 0.6083 - val_loss: 0.9499\n",
            "Epoch 52/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6114 - loss: 0.9472 - val_accuracy: 0.6097 - val_loss: 0.9461\n",
            "Epoch 53/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6075 - loss: 0.9491 - val_accuracy: 0.6128 - val_loss: 0.9389\n",
            "Epoch 54/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6076 - loss: 0.9510 - val_accuracy: 0.6127 - val_loss: 0.9424\n",
            "Epoch 55/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6089 - loss: 0.9531 - val_accuracy: 0.6119 - val_loss: 0.9393\n",
            "Epoch 56/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6089 - loss: 0.9440 - val_accuracy: 0.6072 - val_loss: 0.9452\n",
            "Epoch 57/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6138 - loss: 0.9433 - val_accuracy: 0.6153 - val_loss: 0.9358\n",
            "Epoch 58/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6063 - loss: 0.9516 - val_accuracy: 0.6185 - val_loss: 0.9326\n",
            "Epoch 59/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6091 - loss: 0.9438 - val_accuracy: 0.6138 - val_loss: 0.9329\n",
            "Epoch 60/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6122 - loss: 0.9449 - val_accuracy: 0.6109 - val_loss: 0.9446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Bésqueda de hiperparametros\n",
        "def crear_modelo(units1, units2, units3=None, lr=0.001):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(units1, activation='relu',\n",
        "                                    kernel_initializer=HeNormal(),\n",
        "                                    input_shape=(input_dim,)))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(units2, activation='relu',\n",
        "                                    kernel_initializer=HeNormal()))\n",
        "\n",
        "    if units3:\n",
        "        model.add(tf.keras.layers.Dense(units3, activation='relu',\n",
        "                                        kernel_initializer=HeNormal()))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "1XoyM4yPpSEd"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"===== MODELO A =====\")\n",
        "model_A = crear_modelo(64, 32, lr=0.001)\n",
        "history_A = model_A.fit(train_dataset, validation_data=val_dataset, epochs=60)\n",
        "\n",
        "print(\"\\n===== MODELO B =====\")\n",
        "model_B = crear_modelo(128, 64, 32, lr=0.001)\n",
        "history_B = model_B.fit(train_dataset, validation_data=val_dataset, epochs=60)\n",
        "\n",
        "print(\"\\n===== MODELO C =====\")\n",
        "model_C = crear_modelo(256, 128, 64, lr=0.0005)\n",
        "history_C = model_C.fit(train_dataset, validation_data=val_dataset, epochs=60)\n",
        "\n",
        "# Cambio de batch size\n",
        "train_dataset_64 = train_dataset.unbatch().batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset_64 = val_dataset.unbatch().batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"\\n===== MODELO D =====\")\n",
        "model_D = crear_modelo(256, 128, 64, lr=0.0005)\n",
        "history_D = model_D.fit(train_dataset_64,\n",
        "                        validation_data=val_dataset_64,\n",
        "                        epochs=80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLJ_Z1iFruen",
        "outputId": "0fbc3f95-8208-4bb3-9fcf-e3e6e5e08985"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== MODELO A =====\n",
            "Epoch 1/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4862 - loss: 1.3056 - val_accuracy: 0.5353 - val_loss: 1.1275\n",
            "Epoch 2/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5453 - loss: 1.1177 - val_accuracy: 0.5529 - val_loss: 1.1092\n",
            "Epoch 3/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5494 - loss: 1.1078 - val_accuracy: 0.5492 - val_loss: 1.1058\n",
            "Epoch 4/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5480 - loss: 1.0974 - val_accuracy: 0.5548 - val_loss: 1.0913\n",
            "Epoch 5/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5540 - loss: 1.0958 - val_accuracy: 0.5636 - val_loss: 1.0816\n",
            "Epoch 6/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5598 - loss: 1.0865 - val_accuracy: 0.5564 - val_loss: 1.0825\n",
            "Epoch 7/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5644 - loss: 1.0725 - val_accuracy: 0.5700 - val_loss: 1.0546\n",
            "Epoch 8/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5653 - loss: 1.0733 - val_accuracy: 0.5739 - val_loss: 1.0583\n",
            "Epoch 9/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5646 - loss: 1.0669 - val_accuracy: 0.5642 - val_loss: 1.0652\n",
            "Epoch 10/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5674 - loss: 1.0631 - val_accuracy: 0.5695 - val_loss: 1.0583\n",
            "Epoch 11/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5702 - loss: 1.0654 - val_accuracy: 0.5737 - val_loss: 1.0538\n",
            "Epoch 12/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5754 - loss: 1.0488 - val_accuracy: 0.5754 - val_loss: 1.0458\n",
            "Epoch 13/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5740 - loss: 1.0505 - val_accuracy: 0.5765 - val_loss: 1.0514\n",
            "Epoch 14/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5748 - loss: 1.0469 - val_accuracy: 0.5805 - val_loss: 1.0411\n",
            "Epoch 15/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5805 - loss: 1.0408 - val_accuracy: 0.5777 - val_loss: 1.0319\n",
            "Epoch 16/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5762 - loss: 1.0468 - val_accuracy: 0.5793 - val_loss: 1.0396\n",
            "Epoch 17/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5803 - loss: 1.0451 - val_accuracy: 0.5757 - val_loss: 1.0476\n",
            "Epoch 18/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5784 - loss: 1.0427 - val_accuracy: 0.5770 - val_loss: 1.0453\n",
            "Epoch 19/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5806 - loss: 1.0411 - val_accuracy: 0.5833 - val_loss: 1.0380\n",
            "Epoch 20/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5773 - loss: 1.0434 - val_accuracy: 0.5851 - val_loss: 1.0315\n",
            "Epoch 21/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5818 - loss: 1.0358 - val_accuracy: 0.5868 - val_loss: 1.0311\n",
            "Epoch 22/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5733 - loss: 1.0500 - val_accuracy: 0.5776 - val_loss: 1.0294\n",
            "Epoch 23/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5834 - loss: 1.0243 - val_accuracy: 0.5813 - val_loss: 1.0277\n",
            "Epoch 24/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5841 - loss: 1.0301 - val_accuracy: 0.5822 - val_loss: 1.0374\n",
            "Epoch 25/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5840 - loss: 1.0377 - val_accuracy: 0.5834 - val_loss: 1.0337\n",
            "Epoch 26/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5848 - loss: 1.0295 - val_accuracy: 0.5874 - val_loss: 1.0212\n",
            "Epoch 27/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5877 - loss: 1.0220 - val_accuracy: 0.5763 - val_loss: 1.0373\n",
            "Epoch 28/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 1.0214 - val_accuracy: 0.5859 - val_loss: 1.0191\n",
            "Epoch 29/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5825 - loss: 1.0280 - val_accuracy: 0.5906 - val_loss: 1.0142\n",
            "Epoch 30/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5843 - loss: 1.0269 - val_accuracy: 0.5914 - val_loss: 1.0075\n",
            "Epoch 31/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5830 - loss: 1.0251 - val_accuracy: 0.5899 - val_loss: 1.0149\n",
            "Epoch 32/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5864 - loss: 1.0201 - val_accuracy: 0.5783 - val_loss: 1.0252\n",
            "Epoch 33/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5870 - loss: 1.0146 - val_accuracy: 0.5831 - val_loss: 1.0235\n",
            "Epoch 34/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 1.0122 - val_accuracy: 0.5928 - val_loss: 1.0042\n",
            "Epoch 35/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5862 - loss: 1.0162 - val_accuracy: 0.5837 - val_loss: 1.0189\n",
            "Epoch 36/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5842 - loss: 1.0206 - val_accuracy: 0.5856 - val_loss: 1.0158\n",
            "Epoch 37/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 1.0132 - val_accuracy: 0.5903 - val_loss: 1.0071\n",
            "Epoch 38/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 1.0144 - val_accuracy: 0.5946 - val_loss: 0.9994\n",
            "Epoch 39/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5895 - loss: 1.0105 - val_accuracy: 0.5916 - val_loss: 1.0042\n",
            "Epoch 40/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5877 - loss: 1.0139 - val_accuracy: 0.5943 - val_loss: 1.0073\n",
            "Epoch 41/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 1.0094 - val_accuracy: 0.5940 - val_loss: 0.9993\n",
            "Epoch 42/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5883 - loss: 1.0111 - val_accuracy: 0.5910 - val_loss: 1.0123\n",
            "Epoch 43/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5960 - loss: 1.0055 - val_accuracy: 0.5929 - val_loss: 0.9992\n",
            "Epoch 44/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5955 - loss: 1.0022 - val_accuracy: 0.5888 - val_loss: 1.0215\n",
            "Epoch 45/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5917 - loss: 1.0070 - val_accuracy: 0.5931 - val_loss: 1.0082\n",
            "Epoch 46/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5951 - loss: 1.0057 - val_accuracy: 0.6008 - val_loss: 0.9956\n",
            "Epoch 47/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 0.9963 - val_accuracy: 0.5964 - val_loss: 1.0063\n",
            "Epoch 48/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5878 - loss: 1.0089 - val_accuracy: 0.5964 - val_loss: 0.9976\n",
            "Epoch 49/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: 1.0013 - val_accuracy: 0.5955 - val_loss: 0.9965\n",
            "Epoch 50/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5928 - loss: 1.0082 - val_accuracy: 0.5971 - val_loss: 0.9940\n",
            "Epoch 51/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5951 - loss: 0.9983 - val_accuracy: 0.5931 - val_loss: 1.0053\n",
            "Epoch 52/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5933 - loss: 1.0008 - val_accuracy: 0.5968 - val_loss: 0.9895\n",
            "Epoch 53/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5939 - loss: 1.0048 - val_accuracy: 0.5929 - val_loss: 1.0026\n",
            "Epoch 54/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 0.9932 - val_accuracy: 0.5937 - val_loss: 0.9979\n",
            "Epoch 55/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5915 - loss: 1.0059 - val_accuracy: 0.5996 - val_loss: 0.9823\n",
            "Epoch 56/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5985 - loss: 0.9888 - val_accuracy: 0.5938 - val_loss: 0.9940\n",
            "Epoch 57/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5952 - loss: 1.0053 - val_accuracy: 0.5921 - val_loss: 0.9939\n",
            "Epoch 58/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5932 - loss: 0.9984 - val_accuracy: 0.6022 - val_loss: 0.9899\n",
            "Epoch 59/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5967 - loss: 0.9937 - val_accuracy: 0.5964 - val_loss: 0.9959\n",
            "Epoch 60/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5960 - loss: 0.9934 - val_accuracy: 0.5992 - val_loss: 0.9871\n",
            "\n",
            "===== MODELO B =====\n",
            "Epoch 1/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5133 - loss: 1.2238 - val_accuracy: 0.5529 - val_loss: 1.0981\n",
            "Epoch 2/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5403 - loss: 1.1140 - val_accuracy: 0.5566 - val_loss: 1.0922\n",
            "Epoch 3/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5565 - loss: 1.0989 - val_accuracy: 0.5645 - val_loss: 1.0857\n",
            "Epoch 4/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5569 - loss: 1.0817 - val_accuracy: 0.5611 - val_loss: 1.0778\n",
            "Epoch 5/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5615 - loss: 1.0782 - val_accuracy: 0.5682 - val_loss: 1.0574\n",
            "Epoch 6/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5690 - loss: 1.0623 - val_accuracy: 0.5685 - val_loss: 1.0511\n",
            "Epoch 7/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5686 - loss: 1.0679 - val_accuracy: 0.5838 - val_loss: 1.0314\n",
            "Epoch 8/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5784 - loss: 1.0424 - val_accuracy: 0.5750 - val_loss: 1.0470\n",
            "Epoch 9/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5766 - loss: 1.0443 - val_accuracy: 0.5729 - val_loss: 1.0357\n",
            "Epoch 10/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5788 - loss: 1.0366 - val_accuracy: 0.5762 - val_loss: 1.0433\n",
            "Epoch 11/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5833 - loss: 1.0312 - val_accuracy: 0.5830 - val_loss: 1.0351\n",
            "Epoch 12/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5817 - loss: 1.0328 - val_accuracy: 0.5863 - val_loss: 1.0141\n",
            "Epoch 13/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5869 - loss: 1.0193 - val_accuracy: 0.5813 - val_loss: 1.0240\n",
            "Epoch 14/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5804 - loss: 1.0324 - val_accuracy: 0.5911 - val_loss: 1.0091\n",
            "Epoch 15/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5866 - loss: 1.0147 - val_accuracy: 0.5880 - val_loss: 1.0068\n",
            "Epoch 16/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5878 - loss: 1.0133 - val_accuracy: 0.5890 - val_loss: 1.0130\n",
            "Epoch 17/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5861 - loss: 1.0143 - val_accuracy: 0.5892 - val_loss: 1.0092\n",
            "Epoch 18/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5859 - loss: 1.0083 - val_accuracy: 0.5851 - val_loss: 1.0123\n",
            "Epoch 19/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5837 - loss: 1.0176 - val_accuracy: 0.5921 - val_loss: 1.0005\n",
            "Epoch 20/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5924 - loss: 1.0054 - val_accuracy: 0.5955 - val_loss: 1.0092\n",
            "Epoch 21/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 0.9988 - val_accuracy: 0.5884 - val_loss: 1.0174\n",
            "Epoch 22/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5903 - loss: 1.0114 - val_accuracy: 0.5909 - val_loss: 0.9941\n",
            "Epoch 23/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.9957 - val_accuracy: 0.5938 - val_loss: 0.9872\n",
            "Epoch 24/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5947 - loss: 0.9979 - val_accuracy: 0.5998 - val_loss: 0.9812\n",
            "Epoch 25/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5959 - loss: 0.9883 - val_accuracy: 0.5978 - val_loss: 0.9911\n",
            "Epoch 26/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5901 - loss: 1.0038 - val_accuracy: 0.5893 - val_loss: 0.9974\n",
            "Epoch 27/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5939 - loss: 0.9992 - val_accuracy: 0.6006 - val_loss: 0.9831\n",
            "Epoch 28/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5945 - loss: 0.9895 - val_accuracy: 0.5877 - val_loss: 0.9983\n",
            "Epoch 29/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.9836 - val_accuracy: 0.6055 - val_loss: 0.9700\n",
            "Epoch 30/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5931 - loss: 0.9865 - val_accuracy: 0.6039 - val_loss: 0.9681\n",
            "Epoch 31/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5996 - loss: 0.9857 - val_accuracy: 0.6008 - val_loss: 0.9725\n",
            "Epoch 32/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5994 - loss: 0.9836 - val_accuracy: 0.6100 - val_loss: 0.9604\n",
            "Epoch 33/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5968 - loss: 0.9806 - val_accuracy: 0.6019 - val_loss: 0.9673\n",
            "Epoch 34/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.9686 - val_accuracy: 0.6082 - val_loss: 0.9726\n",
            "Epoch 35/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6001 - loss: 0.9783 - val_accuracy: 0.6001 - val_loss: 0.9784\n",
            "Epoch 36/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6064 - loss: 0.9721 - val_accuracy: 0.6047 - val_loss: 0.9649\n",
            "Epoch 37/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.9701 - val_accuracy: 0.6029 - val_loss: 0.9679\n",
            "Epoch 38/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.9802 - val_accuracy: 0.6066 - val_loss: 0.9686\n",
            "Epoch 39/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5948 - loss: 0.9821 - val_accuracy: 0.6069 - val_loss: 0.9709\n",
            "Epoch 40/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6052 - loss: 0.9627 - val_accuracy: 0.6116 - val_loss: 0.9551\n",
            "Epoch 41/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6011 - loss: 0.9684 - val_accuracy: 0.6014 - val_loss: 0.9682\n",
            "Epoch 42/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6035 - loss: 0.9676 - val_accuracy: 0.6109 - val_loss: 0.9503\n",
            "Epoch 43/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6039 - loss: 0.9611 - val_accuracy: 0.6098 - val_loss: 0.9607\n",
            "Epoch 44/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6043 - loss: 0.9746 - val_accuracy: 0.6087 - val_loss: 0.9641\n",
            "Epoch 45/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6097 - loss: 0.9646 - val_accuracy: 0.5990 - val_loss: 0.9710\n",
            "Epoch 46/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6065 - loss: 0.9639 - val_accuracy: 0.6033 - val_loss: 0.9659\n",
            "Epoch 47/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6028 - loss: 0.9695 - val_accuracy: 0.6080 - val_loss: 0.9597\n",
            "Epoch 48/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6080 - loss: 0.9601 - val_accuracy: 0.6095 - val_loss: 0.9505\n",
            "Epoch 49/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6080 - loss: 0.9590 - val_accuracy: 0.6195 - val_loss: 0.9360\n",
            "Epoch 50/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6114 - loss: 0.9493 - val_accuracy: 0.6091 - val_loss: 0.9519\n",
            "Epoch 51/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6065 - loss: 0.9581 - val_accuracy: 0.6023 - val_loss: 0.9606\n",
            "Epoch 52/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6056 - loss: 0.9568 - val_accuracy: 0.6133 - val_loss: 0.9421\n",
            "Epoch 53/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6066 - loss: 0.9615 - val_accuracy: 0.6084 - val_loss: 0.9448\n",
            "Epoch 54/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6097 - loss: 0.9539 - val_accuracy: 0.6105 - val_loss: 0.9505\n",
            "Epoch 55/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6074 - loss: 0.9526 - val_accuracy: 0.6109 - val_loss: 0.9438\n",
            "Epoch 56/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6131 - loss: 0.9477 - val_accuracy: 0.6113 - val_loss: 0.9429\n",
            "Epoch 57/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6102 - loss: 0.9507 - val_accuracy: 0.6089 - val_loss: 0.9442\n",
            "Epoch 58/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 0.9520 - val_accuracy: 0.6116 - val_loss: 0.9464\n",
            "Epoch 59/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6117 - loss: 0.9522 - val_accuracy: 0.6083 - val_loss: 0.9418\n",
            "Epoch 60/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6071 - loss: 0.9543 - val_accuracy: 0.6158 - val_loss: 0.9413\n",
            "\n",
            "===== MODELO C =====\n",
            "Epoch 1/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5103 - loss: 1.2282 - val_accuracy: 0.5504 - val_loss: 1.1083\n",
            "Epoch 2/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5483 - loss: 1.1033 - val_accuracy: 0.5537 - val_loss: 1.0994\n",
            "Epoch 3/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5583 - loss: 1.0822 - val_accuracy: 0.5574 - val_loss: 1.0919\n",
            "Epoch 4/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5566 - loss: 1.0873 - val_accuracy: 0.5606 - val_loss: 1.0672\n",
            "Epoch 5/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5646 - loss: 1.0762 - val_accuracy: 0.5682 - val_loss: 1.0597\n",
            "Epoch 6/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5680 - loss: 1.0639 - val_accuracy: 0.5753 - val_loss: 1.0356\n",
            "Epoch 7/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.5677 - loss: 1.0682 - val_accuracy: 0.5731 - val_loss: 1.0503\n",
            "Epoch 8/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5765 - loss: 1.0476 - val_accuracy: 0.5716 - val_loss: 1.0554\n",
            "Epoch 9/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5797 - loss: 1.0458 - val_accuracy: 0.5900 - val_loss: 1.0221\n",
            "Epoch 10/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5797 - loss: 1.0361 - val_accuracy: 0.5802 - val_loss: 1.0319\n",
            "Epoch 11/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5822 - loss: 1.0347 - val_accuracy: 0.5833 - val_loss: 1.0260\n",
            "Epoch 12/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5787 - loss: 1.0301 - val_accuracy: 0.5919 - val_loss: 1.0156\n",
            "Epoch 13/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5857 - loss: 1.0235 - val_accuracy: 0.5851 - val_loss: 1.0120\n",
            "Epoch 14/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5854 - loss: 1.0165 - val_accuracy: 0.5933 - val_loss: 1.0061\n",
            "Epoch 15/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.5883 - loss: 1.0162 - val_accuracy: 0.5904 - val_loss: 1.0032\n",
            "Epoch 16/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5841 - loss: 1.0197 - val_accuracy: 0.5894 - val_loss: 1.0007\n",
            "Epoch 17/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5890 - loss: 1.0079 - val_accuracy: 0.5951 - val_loss: 0.9915\n",
            "Epoch 18/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5897 - loss: 1.0024 - val_accuracy: 0.5902 - val_loss: 1.0020\n",
            "Epoch 19/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5931 - loss: 0.9942 - val_accuracy: 0.5905 - val_loss: 1.0026\n",
            "Epoch 20/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5919 - loss: 0.9932 - val_accuracy: 0.5971 - val_loss: 0.9853\n",
            "Epoch 21/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5956 - loss: 0.9947 - val_accuracy: 0.5948 - val_loss: 0.9865\n",
            "Epoch 22/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6007 - loss: 0.9849 - val_accuracy: 0.6018 - val_loss: 0.9690\n",
            "Epoch 23/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5972 - loss: 0.9838 - val_accuracy: 0.5981 - val_loss: 0.9806\n",
            "Epoch 24/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.5967 - loss: 0.9853 - val_accuracy: 0.6056 - val_loss: 0.9640\n",
            "Epoch 25/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 0.9771 - val_accuracy: 0.6035 - val_loss: 0.9706\n",
            "Epoch 26/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5953 - loss: 0.9811 - val_accuracy: 0.5971 - val_loss: 0.9776\n",
            "Epoch 27/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6000 - loss: 0.9742 - val_accuracy: 0.6029 - val_loss: 0.9680\n",
            "Epoch 28/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5982 - loss: 0.9811 - val_accuracy: 0.6051 - val_loss: 0.9639\n",
            "Epoch 29/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6108 - loss: 0.9574 - val_accuracy: 0.5993 - val_loss: 0.9761\n",
            "Epoch 30/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5960 - loss: 0.9758 - val_accuracy: 0.6014 - val_loss: 0.9636\n",
            "Epoch 31/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6016 - loss: 0.9626 - val_accuracy: 0.6082 - val_loss: 0.9579\n",
            "Epoch 32/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6031 - loss: 0.9640 - val_accuracy: 0.6111 - val_loss: 0.9549\n",
            "Epoch 33/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6115 - loss: 0.9553 - val_accuracy: 0.6113 - val_loss: 0.9491\n",
            "Epoch 34/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6056 - loss: 0.9628 - val_accuracy: 0.6101 - val_loss: 0.9509\n",
            "Epoch 35/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6005 - loss: 0.9689 - val_accuracy: 0.6173 - val_loss: 0.9463\n",
            "Epoch 36/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6099 - loss: 0.9486 - val_accuracy: 0.6089 - val_loss: 0.9431\n",
            "Epoch 37/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6081 - loss: 0.9534 - val_accuracy: 0.6040 - val_loss: 0.9580\n",
            "Epoch 38/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6100 - loss: 0.9529 - val_accuracy: 0.6101 - val_loss: 0.9448\n",
            "Epoch 39/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6089 - loss: 0.9498 - val_accuracy: 0.6182 - val_loss: 0.9411\n",
            "Epoch 40/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6061 - loss: 0.9494 - val_accuracy: 0.6178 - val_loss: 0.9343\n",
            "Epoch 41/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6165 - loss: 0.9432 - val_accuracy: 0.6189 - val_loss: 0.9442\n",
            "Epoch 42/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6159 - loss: 0.9386 - val_accuracy: 0.6185 - val_loss: 0.9296\n",
            "Epoch 43/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6169 - loss: 0.9384 - val_accuracy: 0.6138 - val_loss: 0.9375\n",
            "Epoch 44/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6107 - loss: 0.9434 - val_accuracy: 0.6152 - val_loss: 0.9422\n",
            "Epoch 45/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6181 - loss: 0.9350 - val_accuracy: 0.6232 - val_loss: 0.9138\n",
            "Epoch 46/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6106 - loss: 0.9382 - val_accuracy: 0.6129 - val_loss: 0.9288\n",
            "Epoch 47/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6144 - loss: 0.9356 - val_accuracy: 0.6124 - val_loss: 0.9313\n",
            "Epoch 48/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6147 - loss: 0.9330 - val_accuracy: 0.6235 - val_loss: 0.9275\n",
            "Epoch 49/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6187 - loss: 0.9296 - val_accuracy: 0.6207 - val_loss: 0.9157\n",
            "Epoch 50/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6150 - loss: 0.9330 - val_accuracy: 0.6142 - val_loss: 0.9259\n",
            "Epoch 51/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6186 - loss: 0.9248 - val_accuracy: 0.6285 - val_loss: 0.9107\n",
            "Epoch 52/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6254 - loss: 0.9181 - val_accuracy: 0.6204 - val_loss: 0.9137\n",
            "Epoch 53/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6241 - loss: 0.9191 - val_accuracy: 0.6134 - val_loss: 0.9365\n",
            "Epoch 54/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6206 - loss: 0.9250 - val_accuracy: 0.6154 - val_loss: 0.9274\n",
            "Epoch 55/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6251 - loss: 0.9152 - val_accuracy: 0.6186 - val_loss: 0.9198\n",
            "Epoch 56/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6203 - loss: 0.9194 - val_accuracy: 0.6210 - val_loss: 0.9208\n",
            "Epoch 57/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 0.9237 - val_accuracy: 0.6339 - val_loss: 0.8992\n",
            "Epoch 58/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6231 - loss: 0.9189 - val_accuracy: 0.6262 - val_loss: 0.9036\n",
            "Epoch 59/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6273 - loss: 0.9127 - val_accuracy: 0.6294 - val_loss: 0.9086\n",
            "Epoch 60/60\n",
            "\u001b[1m1296/1296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6222 - loss: 0.9119 - val_accuracy: 0.6130 - val_loss: 0.9198\n",
            "\n",
            "===== MODELO D =====\n",
            "Epoch 1/80\n",
            "    648/Unknown \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4954 - loss: 1.3189"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4955 - loss: 1.3187 - val_accuracy: 0.5533 - val_loss: 1.1083\n",
            "Epoch 2/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5495 - loss: 1.1069 - val_accuracy: 0.5507 - val_loss: 1.0946\n",
            "Epoch 3/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5561 - loss: 1.0980 - val_accuracy: 0.5562 - val_loss: 1.0903\n",
            "Epoch 4/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5581 - loss: 1.0869 - val_accuracy: 0.5626 - val_loss: 1.0674\n",
            "Epoch 5/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5626 - loss: 1.0795 - val_accuracy: 0.5657 - val_loss: 1.0643\n",
            "Epoch 6/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5676 - loss: 1.0608 - val_accuracy: 0.5661 - val_loss: 1.0571\n",
            "Epoch 7/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5678 - loss: 1.0614 - val_accuracy: 0.5826 - val_loss: 1.0370\n",
            "Epoch 8/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5743 - loss: 1.0533 - val_accuracy: 0.5754 - val_loss: 1.0423\n",
            "Epoch 9/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5745 - loss: 1.0499 - val_accuracy: 0.5721 - val_loss: 1.0448\n",
            "Epoch 10/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5710 - loss: 1.0455 - val_accuracy: 0.5720 - val_loss: 1.0492\n",
            "Epoch 11/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5784 - loss: 1.0410 - val_accuracy: 0.5773 - val_loss: 1.0395\n",
            "Epoch 12/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5761 - loss: 1.0411 - val_accuracy: 0.5747 - val_loss: 1.0358\n",
            "Epoch 13/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5819 - loss: 1.0309 - val_accuracy: 0.5859 - val_loss: 1.0284\n",
            "Epoch 14/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5834 - loss: 1.0292 - val_accuracy: 0.5913 - val_loss: 1.0075\n",
            "Epoch 15/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5810 - loss: 1.0287 - val_accuracy: 0.5845 - val_loss: 1.0143\n",
            "Epoch 16/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5840 - loss: 1.0214 - val_accuracy: 0.5802 - val_loss: 1.0141\n",
            "Epoch 17/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5854 - loss: 1.0158 - val_accuracy: 0.5905 - val_loss: 1.0121\n",
            "Epoch 18/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5887 - loss: 1.0125 - val_accuracy: 0.5957 - val_loss: 0.9975\n",
            "Epoch 19/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5914 - loss: 1.0083 - val_accuracy: 0.5935 - val_loss: 0.9964\n",
            "Epoch 20/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5906 - loss: 1.0063 - val_accuracy: 0.5942 - val_loss: 0.9932\n",
            "Epoch 21/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5929 - loss: 1.0007 - val_accuracy: 0.5999 - val_loss: 0.9985\n",
            "Epoch 22/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5892 - loss: 1.0037 - val_accuracy: 0.5982 - val_loss: 0.9867\n",
            "Epoch 23/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.9861 - val_accuracy: 0.5949 - val_loss: 0.9857\n",
            "Epoch 24/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5956 - loss: 0.9930 - val_accuracy: 0.5953 - val_loss: 0.9867\n",
            "Epoch 25/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5952 - loss: 0.9928 - val_accuracy: 0.5994 - val_loss: 0.9903\n",
            "Epoch 26/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.9837 - val_accuracy: 0.5978 - val_loss: 0.9826\n",
            "Epoch 27/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6009 - loss: 0.9810 - val_accuracy: 0.5941 - val_loss: 0.9786\n",
            "Epoch 28/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 0.9884 - val_accuracy: 0.5979 - val_loss: 0.9758\n",
            "Epoch 29/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5988 - loss: 0.9803 - val_accuracy: 0.5984 - val_loss: 0.9808\n",
            "Epoch 30/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 0.9829 - val_accuracy: 0.6032 - val_loss: 0.9719\n",
            "Epoch 31/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 0.9715 - val_accuracy: 0.5968 - val_loss: 0.9877\n",
            "Epoch 32/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6102 - loss: 0.9619 - val_accuracy: 0.6040 - val_loss: 0.9655\n",
            "Epoch 33/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6007 - loss: 0.9741 - val_accuracy: 0.6062 - val_loss: 0.9655\n",
            "Epoch 34/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.9657 - val_accuracy: 0.6040 - val_loss: 0.9673\n",
            "Epoch 35/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 0.9651 - val_accuracy: 0.6076 - val_loss: 0.9548\n",
            "Epoch 36/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6048 - loss: 0.9639 - val_accuracy: 0.6008 - val_loss: 0.9725\n",
            "Epoch 37/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 0.9676 - val_accuracy: 0.6088 - val_loss: 0.9550\n",
            "Epoch 38/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6014 - loss: 0.9708 - val_accuracy: 0.6134 - val_loss: 0.9381\n",
            "Epoch 39/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6058 - loss: 0.9610 - val_accuracy: 0.6172 - val_loss: 0.9481\n",
            "Epoch 40/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6053 - loss: 0.9604 - val_accuracy: 0.6063 - val_loss: 0.9561\n",
            "Epoch 41/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.6109 - loss: 0.9512 - val_accuracy: 0.6149 - val_loss: 0.9385\n",
            "Epoch 42/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6068 - loss: 0.9486 - val_accuracy: 0.6134 - val_loss: 0.9366\n",
            "Epoch 43/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6068 - loss: 0.9563 - val_accuracy: 0.6113 - val_loss: 0.9441\n",
            "Epoch 44/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6098 - loss: 0.9492 - val_accuracy: 0.6091 - val_loss: 0.9500\n",
            "Epoch 45/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6148 - loss: 0.9468 - val_accuracy: 0.6172 - val_loss: 0.9309\n",
            "Epoch 46/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6140 - loss: 0.9388 - val_accuracy: 0.6095 - val_loss: 0.9377\n",
            "Epoch 47/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6161 - loss: 0.9385 - val_accuracy: 0.6170 - val_loss: 0.9366\n",
            "Epoch 48/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6132 - loss: 0.9429 - val_accuracy: 0.6124 - val_loss: 0.9406\n",
            "Epoch 49/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6132 - loss: 0.9427 - val_accuracy: 0.6077 - val_loss: 0.9422\n",
            "Epoch 50/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6172 - loss: 0.9353 - val_accuracy: 0.6176 - val_loss: 0.9379\n",
            "Epoch 51/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6200 - loss: 0.9325 - val_accuracy: 0.6133 - val_loss: 0.9342\n",
            "Epoch 52/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6184 - loss: 0.9303 - val_accuracy: 0.6203 - val_loss: 0.9311\n",
            "Epoch 53/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.9363 - val_accuracy: 0.6200 - val_loss: 0.9299\n",
            "Epoch 54/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6133 - loss: 0.9452 - val_accuracy: 0.6148 - val_loss: 0.9293\n",
            "Epoch 55/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6206 - loss: 0.9253 - val_accuracy: 0.6185 - val_loss: 0.9227\n",
            "Epoch 56/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6138 - loss: 0.9351 - val_accuracy: 0.6211 - val_loss: 0.9235\n",
            "Epoch 57/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6187 - loss: 0.9273 - val_accuracy: 0.6250 - val_loss: 0.9193\n",
            "Epoch 58/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6162 - loss: 0.9332 - val_accuracy: 0.6217 - val_loss: 0.9119\n",
            "Epoch 59/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6175 - loss: 0.9287 - val_accuracy: 0.6192 - val_loss: 0.9223\n",
            "Epoch 60/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6175 - loss: 0.9249 - val_accuracy: 0.6216 - val_loss: 0.9285\n",
            "Epoch 61/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6213 - loss: 0.9187 - val_accuracy: 0.6229 - val_loss: 0.9125\n",
            "Epoch 62/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6221 - loss: 0.9229 - val_accuracy: 0.6243 - val_loss: 0.9075\n",
            "Epoch 63/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6179 - loss: 0.9255 - val_accuracy: 0.6280 - val_loss: 0.9213\n",
            "Epoch 64/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6240 - loss: 0.9173 - val_accuracy: 0.6173 - val_loss: 0.9148\n",
            "Epoch 65/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6249 - loss: 0.9134 - val_accuracy: 0.6229 - val_loss: 0.9153\n",
            "Epoch 66/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6219 - loss: 0.9180 - val_accuracy: 0.6257 - val_loss: 0.9083\n",
            "Epoch 67/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6223 - loss: 0.9146 - val_accuracy: 0.6232 - val_loss: 0.9066\n",
            "Epoch 68/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6245 - loss: 0.9123 - val_accuracy: 0.6252 - val_loss: 0.8972\n",
            "Epoch 69/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6261 - loss: 0.9094 - val_accuracy: 0.6259 - val_loss: 0.9104\n",
            "Epoch 70/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6255 - loss: 0.9098 - val_accuracy: 0.6272 - val_loss: 0.8950\n",
            "Epoch 71/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6205 - loss: 0.9152 - val_accuracy: 0.6203 - val_loss: 0.9109\n",
            "Epoch 72/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6267 - loss: 0.9072 - val_accuracy: 0.6276 - val_loss: 0.8993\n",
            "Epoch 73/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6214 - loss: 0.9115 - val_accuracy: 0.6280 - val_loss: 0.9001\n",
            "Epoch 74/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6268 - loss: 0.9012 - val_accuracy: 0.6268 - val_loss: 0.9126\n",
            "Epoch 75/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6197 - loss: 0.9148 - val_accuracy: 0.6297 - val_loss: 0.8969\n",
            "Epoch 76/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6248 - loss: 0.9051 - val_accuracy: 0.6393 - val_loss: 0.8868\n",
            "Epoch 77/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6289 - loss: 0.9017 - val_accuracy: 0.6166 - val_loss: 0.9057\n",
            "Epoch 78/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6277 - loss: 0.9043 - val_accuracy: 0.6363 - val_loss: 0.8819\n",
            "Epoch 79/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6307 - loss: 0.8947 - val_accuracy: 0.6283 - val_loss: 0.8968\n",
            "Epoch 80/80\n",
            "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6303 - loss: 0.8975 - val_accuracy: 0.6258 - val_loss: 0.8959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mejor val_accuracy Modelo A:\", max(history_A.history['val_accuracy']))\n",
        "print(\"Mejor val_accuracy Modelo B:\", max(history_B.history['val_accuracy']))\n",
        "print(\"Mejor val_accuracy Modelo C:\", max(history_C.history['val_accuracy']))\n",
        "print(\"Mejor val_accuracy Modelo D:\", max(history_D.history['val_accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6JcxgXl4WmZ",
        "outputId": "8f3837e3-b359-4a75-8bef-2cd870125797"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor val_accuracy Modelo A: 0.6021631956100464\n",
            "Mejor val_accuracy Modelo B: 0.6194843053817749\n",
            "Mejor val_accuracy Modelo C: 0.6339054703712463\n",
            "Mejor val_accuracy Modelo D: 0.6393133997917175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv Untitled2.ipynb mi-repo/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_X3VJAoUdqQ",
        "outputId": "d650278e-5813-4ef9-9ea9-8333b6819bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'Untitled2.ipynb': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}